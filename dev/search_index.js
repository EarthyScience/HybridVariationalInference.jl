var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = HybridVariationalInference","category":"page"},{"location":"#HybridVariationalInference","page":"Home","title":"HybridVariationalInference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for HybridVariationalInference.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [HybridVariationalInference]","category":"page"},{"location":"#HybridVariationalInference.AbstractComponentArrayInterpreter","page":"Home","title":"HybridVariationalInference.AbstractComponentArrayInterpreter","text":"AbstractComponentArrayInterpreter\n\nInterface for Type that implements\n\nas_ca(::AbstractArray, interpreter) -> ComponentArray\nBase.length(interpreter) -> Int\n\nWhen called on a vector, forwards to as_ca.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.AbstractHybridCase","page":"Home","title":"HybridVariationalInference.AbstractHybridCase","text":"Type to dispatch constructing data and network structures for different cases of hybrid problem setups\n\nFor a specific case, provide functions that specify details\n\nget_hybridcase_MLapplicator\nget_hybridcase_PBmodel\nget_hybridcase_neg_logden_obs\nget_hybridcase_par_templates\nget_hybridcase_transforms\nget_hybridcase_train_dataloader (default depends on gen_hybridcase_synthetic)\n\noptionally\n\ngen_hybridcase_synthetic\nget_hybridcase_n_covar (defaults to number of rows in xM in train_dataloader )\nget_hybridcase_float_type (defaults to eltype(θM))\nget_hybridcase_cor_starts (defaults to include all correlations: (P=(1,), M=(1,)))\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.AbstractModelApplicator","page":"Home","title":"HybridVariationalInference.AbstractModelApplicator","text":"AbstractModelApplicator(x, ϕ)\n\nAbstraction of applying a machine learning model at covariate matrix, x, using parameters, ϕ. It returns a matrix of predictions with the same number of rows as in x.    \n\nConstructors for specifics are defined in extension packages. Each constructor takes a special type of machine learning model and returns  a tuple with two components:\n\nThe applicator \na sample parameter vector (type  depends on the used ML-framework)\n\nImplemented are\n\nconstruct_SimpleChainsApplicator\nconstruct_FluxApplicator\nconstruct_LuxApplicator\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.ComponentArrayInterpreter","page":"Home","title":"HybridVariationalInference.ComponentArrayInterpreter","text":"Non-Concrete version of AbstractComponentArrayInterpreter that avoids storing additional type parameters.\n\nDoes not trigger specialization for Interpreters of different axes, but does not allow compiler-inferred length to construct StaticArrays.\n\nUse get_concrete(cai::ComponentArrayInterpreter) to pass a concrete version to  performance-critical functions.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.ComponentArrayInterpreter-Tuple{NamedTuple}","page":"Home","title":"HybridVariationalInference.ComponentArrayInterpreter","text":"ComponentArrayInterpreter(; kwargs...)\nComponentArrayInterpreter(::AbstractComponentArray)\nComponentArrayInterpreter(::AbstractComponentArray, n_dims::NTuple{N,<:Integer})\nComponentArrayInterpreter(n_dims::NTuple{N,<:Integer}, ::AbstractComponentArray)\n\nConstruct a ComponentArrayInterpreter <: AbstractComponentArrayInterpreter with components being vectors of given length or given model of a AbstractComponentArray.\n\nThe other constructors allow constructing arrays with additional dimensions.\n\n'''julia     interpreter = ComponentArrayInterpreter(; P=2, M=(2,3), Unc=5)     v = 1.0:length(interpreter)     interpreter(v).M == 2 .+ [1 3 5; 2 4 6]     vm = stack((v,v .* 10, v .* 100))\n\nintm = ComponentArrayInterpreter(interpreter(v), (3,))\nintm(vm)[:Unc, 2]\n\n'''\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.ComponentArrayInterpreter-Tuple{}","page":"Home","title":"HybridVariationalInference.ComponentArrayInterpreter","text":"ComponentArrayInterpreter(; kwargs...)\nComponentArrayInterpreter(::AbstractComponentArray)\nComponentArrayInterpreter(::AbstractComponentArray, n_dims::NTuple{N,<:Integer})\nComponentArrayInterpreter(n_dims::NTuple{N,<:Integer}, ::AbstractComponentArray)\n\nConstruct a ComponentArrayInterpreter <: AbstractComponentArrayInterpreter with components being vectors of given length or given model of a AbstractComponentArray.\n\nThe other constructors allow constructing arrays with additional dimensions.\n\n'''julia     interpreter = ComponentArrayInterpreter(; P=2, M=(2,3), Unc=5)     v = 1.0:length(interpreter)     interpreter(v).M == 2 .+ [1 3 5; 2 4 6]     vm = stack((v,v .* 10, v .* 100))\n\nintm = ComponentArrayInterpreter(interpreter(v), (3,))\nintm(vm)[:Unc, 2]\n\n'''\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.StaticComponentArrayInterpreter","page":"Home","title":"HybridVariationalInference.StaticComponentArrayInterpreter","text":"Concrete version of AbstractComponentArrayInterpreter that stores an axis in its type signature.\n\nAllows compiler-inferred length to construct StaticArrays, but requires specialization on dispatch when provided as an argument to a function.\n\nUse get_concrete(cai::ComponentArrayInterpreter) to pass a concrete version to  performance-critical functions.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.as_ca","page":"Home","title":"HybridVariationalInference.as_ca","text":"as_ca(v::AbstractArray, interpretor)\n\nReturns a ComponentArray with underlying data v.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.callback_loss","page":"Home","title":"HybridVariationalInference.callback_loss","text":"create a function (state, l) -> false that prints iter and loss each moditer\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.compute_correlated_covars-Union{Tuple{T}, Tuple{Random.AbstractRNG, AbstractMatrix{T}}} where T","page":"Home","title":"HybridVariationalInference.compute_correlated_covars","text":"Create n_covar correlated covariates  from uncorrelated row-wise vector x_pc, with correlations rhos to the linear combinations of x_pc.\n\nBy default correlations, rhos = (1.0),0.88,0.78,0.69,0.61 ...,  decrease exponentially as e^{-i/rhodec}, with rhodec = 8.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.construct_3layer_MLApplicator","page":"Home","title":"HybridVariationalInference.construct_3layer_MLApplicator","text":"construct_3layer_MLApplicator(\n    rng::AbstractRNG, case::HVI.AbstractHybridCase, <ml_engine>;\n    scenario::NTuple = ())\n\nml_engine usually is of type Val{Symbol}, e.g. Val(:Flux). See select_ml_engine.       \n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.construct_ChainsApplicator","page":"Home","title":"HybridVariationalInference.construct_ChainsApplicator","text":"construct_ChainsApplicator([rng::AbstractRNG,] chain, float_type)\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.flatten1-Tuple{ComponentArrays.ComponentVector}","page":"Home","title":"HybridVariationalInference.flatten1","text":"Removes the highest level of keys. Keeps the reference to the underlying data, but changes the axis. If first-level vector has no sub-names, an error (Aguement Error tuple must be non-empty) is thrown.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.front","page":"Home","title":"HybridVariationalInference.front","text":"omit the last n elements of an iterator\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.gen_cov_pred-Tuple{Random.AbstractRNG, DataType, Any, Any, Any, Integer}","page":"Home","title":"HybridVariationalInference.gen_cov_pred","text":"Generate correlated covariates and synthetic true parameters that are a linear combination of the uncorrelated underlying principal  factors and their binary combinations.\n\nIn addition provide a SimpleChains model of adequate complexity to fit this relationship θMstrue = f(xo)\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.gen_hybridcase_synthetic","page":"Home","title":"HybridVariationalInference.gen_hybridcase_synthetic","text":"gen_hybridcase_synthetic([rng,] ::AbstractHybridCase; scenario)\n\nSetup synthetic data, a NamedTuple of\n\nxM: matrix of covariates, with one column per site\nθP_true: vector global process-model parameters\nθMs_true: matrix of site-varying process-model parameters, with \nxP: Vector of process-model drivers, with an entry per site\nyglobaltrue: vector of global observations\ny_true: matrix of site-specific observations with one column per site\nyglobalo, y_o: observations with added noise\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.generate_ζ-Tuple{Any, Any, AbstractVector, AbstractMatrix, NamedTuple}","page":"Home","title":"HybridVariationalInference.generate_ζ","text":"Generate samples of (inv-transformed) model parameters, ζ,  and the vector of standard deviations, σ, i.e. the diagonal of the cholesky-factor.\n\nAdds the MV-normally distributed residuals, retrieved by sample_ζ_norm0 to the means extracted from parameters and predicted by the machine learning model. \n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_ca_starts-Tuple{ComponentArrays.ComponentVector}","page":"Home","title":"HybridVariationalInference.get_ca_starts","text":"get_ca_starts(vc::ComponentVector)\n\nReturn a tuple with starting positions of components in vc.  Useful for providing information on correlactions among subranges in a vector.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridcase_MLapplicator","page":"Home","title":"HybridVariationalInference.get_hybridcase_MLapplicator","text":"get_hybridcase_MLapplicator([rng::AbstractRNG,] ::AbstractHybridCase; scenario=())\n\nConstruct the machine learning model fro given problem case and ML-Framework and  scenario.\n\nreturns a Tuple of\n\nAbstractModelApplicator\ninitial parameter vector\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridcase_PBmodel","page":"Home","title":"HybridVariationalInference.get_hybridcase_PBmodel","text":"get_hybridcase_PBmodel(::AbstractHybridCase; scenario::NTuple=())\n\nConstruct the process-based model function  f(θP::AbstractVector, θMs::AbstractMatrix, x) -> (AbstractVector, AbstractMatrix) with\n\nθP: calibrated parameters that are constant across site\nθMs: calibrated parameters that vary across sites, with a  column for each site\nx: drivers, indexed by site\n\nreturns a tuple of predictions with components\n\nfirst, those that are constant across sites\nsecond, those that vary across sites, with a column for each site\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridcase_cor_starts-Tuple{AbstractHybridCase}","page":"Home","title":"HybridVariationalInference.get_hybridcase_cor_starts","text":"get_hybridcase_cor_starts(case::AbstractHybridCase; scenario)\n\nSpecify blocks in correlation matrices among parameters. Returns a NamedTuple.\n\nP: correlations among global parameters\nM: correlations among ML-predicted parameters\n\nSubsets ofparameters that are correlated with other but not correlated with parameters of other subranges are specified by indicating the starting position of each subrange. E.g. if within global parameter vector (p1, p2, p3), p1 and p2 are correlated,  but parameter p3 is not correlated with them, then the first subrange starts at position 1 and the second subrange starts at position 3. If there is only single block of all ML-predicted parameters being correlated  with each other then this block starts at position 1: (P=(1,3), M=(1,)).\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridcase_float_type-Tuple{AbstractHybridCase}","page":"Home","title":"HybridVariationalInference.get_hybridcase_float_type","text":"get_hybridcase_float_type(::AbstractHybridCase; scenario)\n\nDetermine the FloatType for given Case and scenario, defaults to Float32\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridcase_n_covar-Tuple{AbstractHybridCase}","page":"Home","title":"HybridVariationalInference.get_hybridcase_n_covar","text":"get_hybridcase_n_covar(::AbstractHybridCase; scenario)\n\nProvide the number of covariates. Default returns the number of rows in xM from get_hybridcase_train_dataloader.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridcase_neg_logden_obs","page":"Home","title":"HybridVariationalInference.get_hybridcase_neg_logden_obs","text":"get_hybridcase_neg_logden_obs(::AbstractHybridCase; scenario)\n\nProvide a function(y_obs, ypred) -> Real that computes the negative logdensity of the observations, given the predictions.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridcase_par_templates","page":"Home","title":"HybridVariationalInference.get_hybridcase_par_templates","text":"get_hybridcase_par_templates(::AbstractHybridCase; scenario)\n\nProvide tuple of templates of ComponentVectors θP and θM.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridcase_train_dataloader-Tuple{Random.AbstractRNG, AbstractHybridCase}","page":"Home","title":"HybridVariationalInference.get_hybridcase_train_dataloader","text":"get_hybridcase_train_dataloader([rng,] ::AbstractHybridCase; scenario)\n\nReturn a DataLoader that provides a tuple of\n\nxM: matrix of covariates, with one column per site\nxP: Iterator of process-model drivers, with one element per site\ny_o: matrix of observations with added noise, with one column per site\ny_unc: matrix sizeof(y_o) of uncertainty information \n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridcase_transforms","page":"Home","title":"HybridVariationalInference.get_hybridcase_transforms","text":"get_hybridcase_transforms(::AbstractHybridCase; scenario)\n\nReturn a NamedTupe of\n\ntransP: Bijectors.Transform for the global PBM parameters, θP\ntransM: Bijectors.Transform for the single-site PBM parameters, θM\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_loss_gf-Tuple{Any, Any, Any, Any, HybridVariationalInference.AbstractComponentArrayInterpreter}","page":"Home","title":"HybridVariationalInference.get_loss_gf","text":"Create a loss function for parameter vector p, given \n\ng(x, ϕ): machine learning model \nf(θMs, θP): mechanistic model \nxM: matrix of covariates, sites in columns\ny_o: matrix of observations, sites in columns\nint_ϕθP: interpreter attachin axis with compponents ϕg and pc.θP\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.gf-NTuple{7, Any}","page":"Home","title":"HybridVariationalInference.gf","text":"composition f ∘ transM ∘ g: mechanistic model after machine learning parameter prediction\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.handle_GPU_data-Tuple{AbstractGPUDataHandler, AbstractArray}","page":"Home","title":"HybridVariationalInference.handle_GPU_data","text":"(app::AbstractGPUDataHandler)(x) = handle_GPU_data(app, x)\n\nCallable applied to argument x, used to configure the exchange of data between GPU and CPU. By Default, nothing is done to x. Package extensions for Flux and Lux implement overloads for AbstractGPUArray that call cpu(x) to transfer data on the GPU to CPU. Those package extension also use set_default_GPUHandler() so that .\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.init_hybrid_params-NTuple{4, Any}","page":"Home","title":"HybridVariationalInference.init_hybrid_params","text":"init_hybrid_params(θP, θM, ϕg, n_batch; transP=asℝ, transM=asℝ)\n\nSetup ComponentVector of parameters to optimize, and associated tools. Returns a NamedTuple of\n\nϕ: A ComponentVector of parameters to optimize\ntransPMsbatch, interpreters: Transformations and interpreters as  required by `negelbotransnormgf`.\ngettransPMs: a function returning transformations `(nsite) -> (;P,Ms)`\ngetcaintPMs: a function returning ComponentArrayInterpreter for PMs vector  with PMs shaped as a matrix of `nsitecolumns ofθM`\n\nArguments\n\nθP, θM: Template ComponentVectors of global parameters and ML-predicted parameters\nϕg: vector of parameters to optimize, as returned by get_hybridcase_MLapplicator\nn_batch: the number of sites to predicted in each mini-batch\ntransP, transM: the Bijector.Transformations for the global and site-dependent    parameters, e.g. Stacked(elementwise(identity), elementwise(exp), elementwise(exp)).   Its the transformation froing from unconstrained to constrained space: θ = Tinv(ζ),   because this direction is used much more often.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.invsumn-Tuple{T} where T","page":"Home","title":"HybridVariationalInference.invsumn","text":"Inverse of s = sumn(n) for positive integer n.\n\nGives an inexact error, if given s was not such a sum.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.neg_elbo_transnorm_gf-Tuple{Any, AbstractVector, Any, Any, Any, Any, AbstractMatrix, Any, Any, Any, NamedTuple}","page":"Home","title":"HybridVariationalInference.neg_elbo_transnorm_gf","text":"Cost function (ELBO) for hybrid model with batched sites.\n\nIt generates n_MC samples for each site, and uses these to compute the expected value of the likelihood of observations.\n\nArguments\n\nrng: random number generator (ignored on CUDA, if ϕ is a AbstractGPUArray)\nϕ: flat vector of parameters, interpreted by interpreters interpreted by interpreters.μPϕgunc and interpreters.PMs\ng: machine learning model\ntransPMs: Transformations as generated by gettransPMs returned from inithybrid_params\nf: mechanistic model\npy: negative log-likelihood of observations given predictions:  function(y_ob, y_pred, y_unc)\nxM: matrix of covariates (ncov x nsite_batch)\nxP: model drivers, iterable of (nsitebatch)\ny_ob: matrix of observations (nobs x nsite_batch)\ny_unc: observation uncertainty provided to py (same size as y_ob)\ninterpreters: NamedTuple as generated by gen_hybridcase_synthetic with entries:\nμP_ϕg_unc: extract components of parameter of \nmeans of global PBM, 2) ML-weights, and 3) additional parameters of approximation q\nPMs: assign components to PBM parameters 1 global, 2 matrix of n_site column  vectors\nint_unc (can be omitted, if μP_ϕg_unc(ϕ).unc is already a ComponentVector)\nn_MC: number of MonteCarlo samples from the distribution of parameters to simulate using the mechanistic model f.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.neg_logden_indep_normal-Tuple{AbstractArray, AbstractArray, AbstractArray}","page":"Home","title":"HybridVariationalInference.neg_logden_indep_normal","text":"neg_logden_indep_normal(obs, μ, logσ2s; σfac=1.0)\n\nCompute the negative Log-density of θM for multiple independent normal distributions, given estimated means μ and estimated log of variance parameters logσ2s.\n\nAll the arguments should be vectors of the same length. If obs,  μ are given as a matrix of several column-vectors, their summed Likelihood is computed, assuming each column having the same logσ2s.\n\nKeyword argument σfac can be increased to put more weight on achieving a low uncertainty estimate and means closer to the observations to help an initial fit. The obtained parameters then can be used as starting values for a the proper fit with σfac=1.0.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.predict_gf-Tuple{Any, Any, Any, AbstractVector, AbstractMatrix, Any, Any}","page":"Home","title":"HybridVariationalInference.predict_gf","text":"predict_gf(rng, g, f, ϕ::AbstractVector, xM::AbstractMatrix, interpreters;\n    get_transPMs, get_ca_int_PMs, n_sample_pred=200, \n    gpu_data_handler=get_default_GPUHandler())\n\nPrediction function for hybrid model. Returns an Array (n_obs, n_site, n_sample_pred).\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.predict_y-Tuple{Any, Any, Any, Bijectors.Transform, HybridVariationalInference.AbstractComponentArrayInterpreter}","page":"Home","title":"HybridVariationalInference.predict_y","text":"Compute predictions and log-Determinant of the transformation at given transformed parameters for each site. \n\nThe number of sites is given by the number of columns in Ms, which is determined by the transformation, transPMs.\n\nSteps:\n\ntransform the parameters to original constrained space\nApplies the mechanistic model for each site\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.sample_ζ_norm0-Tuple{Random.AbstractRNG, AbstractVector, AbstractMatrix, Vararg{Any}}","page":"Home","title":"HybridVariationalInference.sample_ζ_norm0","text":"Extract relevant parameters from θ and return n_MC generated draws together with the vector of standard deviations, σ.\n\nArguments\n\nint_unc: Interpret vector as ComponentVector with components    ρsP, ρsM, logσ2logP, coeflogσ2_logMs(intercept + slope), \n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.scale_centered_at","page":"Home","title":"HybridVariationalInference.scale_centered_at","text":"scale_centered_at(x, m, σrel=1.0)\nscale_centered_at(x, m, σ)\n\nCenters and rescales rows of matrix x around vector m. The scale can either be given relative to m or specified as a vector of same size as m.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.select_ml_engine-Tuple{}","page":"Home","title":"HybridVariationalInference.select_ml_engine","text":"select_ml_engine(;scenario)\n\nReturns a value type Val{:Symbol} to dispatch on the machine learning engine to use.\n\ndefaults to Val(:SimpleChains)\n:use_Lux ∈ scenario -> Val(:Lux)\n:use_Flux ∈ scenario -> Val(:Flux)\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.transformU_block_cholesky1","page":"Home","title":"HybridVariationalInference.transformU_block_cholesky1","text":"transformU_block_cholesky1(v::AbstractVector, cor_starts = (1,))\n\nTransform a parameterization v of a blockdiagonal of upper triangular matrices into the this matrix. cor_starts is a NTuple of Integeres specifying the first column of each block.  E.g. For a matrix with a 3x3, a 2x2, and another block,  the blocks start at columns (1,4,6). It defaults to a single entire block.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.transformU_cholesky1-Tuple{AbstractVector}","page":"Home","title":"HybridVariationalInference.transformU_cholesky1","text":"Takes a vector of entries of a lower UnitUpperTriangular matrix and transforms it to an UpperTriangular that satisfies  diag(U' * U) = 1.\n\nThis can be used to fit parameters that yield an upper Cholesky-Factor of a Covariance matrix.\n\nIt uses the upper triangular matrix rather than the lower because it involes a sum across columns, whereas the alternative of a lower triangular uses sum across rows.  Sum across columns is often faster, because entries of columns are contiguous.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.utri2vec-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T","page":"Home","title":"HybridVariationalInference.utri2vec","text":"Extract entries of upper diagonal matrix of UppterTriangular to columnwise vector\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.utri2vec_pos-Tuple{Any, Any}","page":"Home","title":"HybridVariationalInference.utri2vec_pos","text":"Compute the index in the vector of entries in an upper tridiagonal matrix\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.uutri2vec-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T","page":"Home","title":"HybridVariationalInference.uutri2vec","text":"Extract entries of upper diagonal matrix of UnitUppterTriangular to columnwise vector\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.vec2utri-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T","page":"Home","title":"HybridVariationalInference.vec2utri","text":"Convert vector v columnwise entries of upper diagonal matrix to UppterTriangular\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.vec2utri_pos-Tuple{Any, Any}","page":"Home","title":"HybridVariationalInference.vec2utri_pos","text":"Compute the (one-based) position (row, col) within an upper tridiagonal matrix for given (one-based) position, s within a packed vector representation.\n\n\n\n\n\n","category":"method"}]
}
