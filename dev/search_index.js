var documenterSearchIndex = {"docs":
[{"location":"#HybridVariationalInference","page":"Home","title":"HybridVariationalInference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for HybridVariationalInference.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#HybridVariationalInference.AbstractComponentArrayInterpreter","page":"Home","title":"HybridVariationalInference.AbstractComponentArrayInterpreter","text":"AbstractComponentArrayInterpreter\n\nInterface for Type that implements\n\nas_ca(::AbstractArray, interpreter) -> ComponentArray\nComponentArrays.getaxes(interpreter)\nBase.length(interpreter) -> Int\n\nWhen called on a vector, forwards to as_ca.\n\nThere is a default implementation for Base.length based on ComponentArrays.getaxes.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.AbstractHybridProblem","page":"Home","title":"HybridVariationalInference.AbstractHybridProblem","text":"Type to dispatch constructing data and network structures for different cases of hybrid problem setups.\n\nFor a specific prob, provide functions that specify details\n\nget_hybridproblem_MLapplicator\nget_hybridproblem_transforms\nget_hybridproblem_PBmodel\nget_hybridproblem_neg_logden_obs\nget_hybridproblem_par_templates\nget_hybridproblem_ϕunc\nget_hybridproblem_train_dataloader (may use construct_dataloader_from_synthetic)\nget_hybridproblem_priors \nget_hybridproblem_n_covar \nget_hybridproblem_n_site_and_batch \n\noptionally\n\ngen_hybridproblem_synthetic\nget_hybridproblem_float_type (defaults to eltype(θM))\nget_hybridproblem_cor_ends (defaults to include all correlations:  (P = [length(θP)], M = [length(θM)]))\nget_hybridproblem_pbmpar_covars (defaults to empty tuple)\n\nThe initial value of parameters to estimate is spread\n\nϕg: parameter of the MLapplicator: returned by get_hybridproblem_MLapplicator\nζP: mean of the PBmodel parameters: returned by get_hybridproblem_par_templates\nϕunc: additional parameters of the approximte posterior: returned by get_hybridproblem_ϕunc\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.AbstractModelApplicator","page":"Home","title":"HybridVariationalInference.AbstractModelApplicator","text":"AbstractModelApplicator(x, ϕ)\n\nAbstraction of applying a machine learning model at covariate matrix, x, using parameters, ϕ. It returns a matrix of predictions with the same number of rows as in x.    \n\nConstructors for specifics are defined in extension packages. Each constructor takes a special type of machine learning model and returns  a tuple with two components:\n\nThe applicator \na sample parameter vector (type  depends on the used ML-framework)\n\nImplemented are\n\nconstruct_SimpleChainsApplicator\nconstruct_FluxApplicator\nconstruct_LuxApplicator\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.ComponentArrayInterpreter","page":"Home","title":"HybridVariationalInference.ComponentArrayInterpreter","text":"Non-Concrete version of AbstractComponentArrayInterpreter that avoids storing additional type parameters.\n\nDoes not trigger specialization for Interpreters of different axes, but does not allow compiler-inferred length to construct StaticArrays.\n\nUse get_concrete(cai::ComponentArrayInterpreter) to pass a concrete version to  performance-critical functions.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.ComponentArrayInterpreter-Tuple{}","page":"Home","title":"HybridVariationalInference.ComponentArrayInterpreter","text":"ComponentArrayInterpreter(; kwargs...)\nComponentArrayInterpreter(::AbstractComponentArray)\nComponentArrayInterpreter(::AbstractComponentArray, n_dims::NTuple{N,<:Integer})\nComponentArrayInterpreter(n_dims::NTuple{N,<:Integer}, ::AbstractComponentArray)\n\nConstruct a ComponentArrayInterpreter <: AbstractComponentArrayInterpreter with components being vectors of given length or given model of a AbstractComponentArray.\n\nThe other constructors allow constructing arrays with additional dimensions.\n\n'''julia     interpreter = ComponentArrayInterpreter(; P=2, M=(2,3), Unc=5)     v = 1.0:length(interpreter)     interpreter(v).M == 2 .+ [1 3 5; 2 4 6]     vm = stack((v,v .* 10, v .* 100))\n\nintm = ComponentArrayInterpreter(interpreter(v), (3,))\nintm(vm)[:Unc, 2]\n\n'''\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.MagnitudeModelApplicator","page":"Home","title":"HybridVariationalInference.MagnitudeModelApplicator","text":"MagnitudeModelApplicator(app, y0)\n\nWrapper around AbstractModelApplicator that multiplies the prediction by the absolute inverse of an initial estimate of the prediction.\n\nThis helps to keep raw predictions and weights in a similar magnitude.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.NormalScalingModelApplicator","page":"Home","title":"HybridVariationalInference.NormalScalingModelApplicator","text":"NormalScalingModelApplicator(app, μ, σ)\nNormalScalingModelApplicator(app, priors, transM)\n\nWrapper around AbstractModelApplicator that transforms each output  (assumed in [0..1], such as output of logistic activation function) to a quantile of a Normal distribution. \n\nLength of μ, σ must correspond to the number of outputs of the wrapped ModelApplicator.\n\nThis helps to keep raw ML-predictions (in confidence bounds) and weights in a  similar magnitude. Compared to specifying bounds, this allows for the possibility  (although harder to converge) far beyond the confidence bounds.\n\nThe second constructor fits a normal distribution of the inverse-transformed 5% and 95% quantiles of prior distributions.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.NormalScalingModelApplicator-Tuple{AbstractModelApplicator, AbstractVector{<:Number}, Any, Type}","page":"Home","title":"HybridVariationalInference.NormalScalingModelApplicator","text":"Fit a Normal distribution to iterators lower and upper.  If repeat_inner is given, each fitted distribution is repeated as many times.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.NullModelApplicator","page":"Home","title":"HybridVariationalInference.NullModelApplicator","text":"NullModelApplicator()\n\nModel applicator that returns its inputs. Used for testing.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.StackedArray","page":"Home","title":"HybridVariationalInference.StackedArray","text":"StackedArray(stacked, nrow)\n\nA Bijectors.Transform that applies stacked to each column of an n-row matrix.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.StaticComponentArrayInterpreter","page":"Home","title":"HybridVariationalInference.StaticComponentArrayInterpreter","text":"Concrete version of AbstractComponentArrayInterpreter that stores an axis in its type signature.\n\nAllows compiler-inferred length to construct StaticArrays, but requires specialization on dispatch when provided as an argument to a function.\n\nUse get_concrete(cai::ComponentArrayInterpreter) to pass a concrete version to  performance-critical functions.\n\n\n\n\n\n","category":"type"},{"location":"#HybridVariationalInference.apply_f_trans-Tuple{AbstractMatrix, AbstractArray, Any, Any}","page":"Home","title":"HybridVariationalInference.apply_f_trans","text":"Compute predictions of the transformation at given transformed parameters for each site.  The number of sites is given by the number of rows in ζsMs.\n\nSteps:\n\ntransform the parameters to original constrained space\nApplies the mechanistic model for each site\n\nζsP and ζsMs are shaped according to the output of generate_ζ. Results are of shape (n_obs x n_site_pred x n_MC).\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.as_ca","page":"Home","title":"HybridVariationalInference.as_ca","text":"as_ca(v::AbstractArray, interpretor)\n\nReturns a ComponentArray with underlying data v.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.callback_loss","page":"Home","title":"HybridVariationalInference.callback_loss","text":"create a function (state, l) -> false that prints iter and loss each moditer\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.compose_axes-Tuple{NamedTuple}","page":"Home","title":"HybridVariationalInference.compose_axes","text":"compose_axes(axtuples::NamedTuple)\n\nCreate a new 1d-axis that combines several other named axes-tuples such as of key = getaxes(::AbstractComponentArray).\n\nThe new axis consists of several ViewAxes. If an axis-tuple consists only of one axis, it is used for the view. Otherwise a ShapedAxis is created with the axes-length of the others, essentially dropping component information that might be present in the dimensions.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.compute_cholcor_coefficient_single-Tuple{Any}","page":"Home","title":"HybridVariationalInference.compute_cholcor_coefficient_single","text":"Compute the cholesky-factor parameter for a given single correlation in a 2x2 matrix. Invert the transformation of cholesky-factor parameterization.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.compute_correlated_covars-Union{Tuple{T}, Tuple{Random.AbstractRNG, AbstractMatrix{T}}} where T","page":"Home","title":"HybridVariationalInference.compute_correlated_covars","text":"Create n_covar correlated covariates  from uncorrelated row-wise vector x_pc, with correlations rhos to the linear combinations of x_pc.\n\nBy default correlations, rhos = (1.0),0.88,0.78,0.69,0.61 ...,  decrease exponentially as e^{-i/rhodec}, with rhodec = 8.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.compute_elbo_components-Tuple{AbstractHybridProblem, HybridPosteriorSolver}","page":"Home","title":"HybridVariationalInference.compute_elbo_components","text":"Compute the components of the elbo for given initial conditions of the problems for the first batch of the trainloader.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.construct_3layer_MLApplicator","page":"Home","title":"HybridVariationalInference.construct_3layer_MLApplicator","text":"construct_3layer_MLApplicator(\n    rng::AbstractRNG, prob::HVI.AbstractHybridProblem, <ml_engine>;\n    scenario::Val{scen}) where scen\n\nConstruct a machine learning model for given Proglem and machine learning engine. Implemented for machine learning extensions, such as Flux or SimpleChains. ml_engine usually is of type Val{Symbol}, e.g. Val(:Flux). See select_ml_engine.       \n\nScenario is a value-type of NTuple{_,Symbol}.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.construct_ChainsApplicator","page":"Home","title":"HybridVariationalInference.construct_ChainsApplicator","text":"construct_ChainsApplicator([rng::AbstractRNG,] chain, float_type)\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.construct_dataloader_from_synthetic-Tuple{Random.AbstractRNG, AbstractHybridProblem}","page":"Home","title":"HybridVariationalInference.construct_dataloader_from_synthetic","text":"construct_dataloader_from_synthetic(rng::AbstractRNG, prob::AbstractHybridProblem;\n    scenario = (), n_batch)\n\nConstruct a dataloader based on gen_hybridproblem_synthetic. \n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.construct_partric-Tuple{AbstractModelApplicator, Any, Any}","page":"Home","title":"HybridVariationalInference.construct_partric","text":"Construct a parametric type-stable model applicator, given covariates, x, and parameters, ϕ.\n\nThe default returns the current model applicator.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.construct_priors_θ_mean-Union{Tuple{scen}, NTuple{8, Any}} where scen","page":"Home","title":"HybridVariationalInference.construct_priors_θ_mean","text":"In order to let mean of θ stay close to initial point parameter estimates  construct a prior on mean θ to a Normal around initial prediction.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.cpu_ca","page":"Home","title":"HybridVariationalInference.cpu_ca","text":"cpu_ca(ca::CA.ComponentArray)\n\nMove ComponentArray form gpu to cpu.    \n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.extend_stacked_nrow-Tuple{Bijectors.Stacked, Integer}","page":"Home","title":"HybridVariationalInference.extend_stacked_nrow","text":"extend_stacked_nrow(b::Stacked, nrow::Integer)\n\nCreate a Stacked bijectors that transforms nrow times the elements of the original Stacked bijector.\n\nExample\n\nX = reduce(hcat, ([x + y for x in 0:4 ] for y in 0:10:30))\nb1 = CP.Exp()\nb2 = identity\nb = Stacked((b1,b2), (1:1,2:4))\nbs = extend_stacked_nrow(b, size(X,1))\nXt = reshape(bs(vec(X)), size(X))\n@test Xt[:,1] == b1(X[:,1])\n@test Xt[:,2:4] == b2(X[:,2:4])\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.flatten1-Tuple{ComponentArrays.ComponentVector}","page":"Home","title":"HybridVariationalInference.flatten1","text":"flatten1(cv::CA.ComponentVector)\n\nRemoves the highest level of keys. Keeps the reference to the underlying data, but changes the axis. If first-level vector has no sub-names, an error (Aguement Error tuple must be non-empty) is thrown.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.front","page":"Home","title":"HybridVariationalInference.front","text":"omit the last n elements of an iterator\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.gdev_hybridproblem_dataloader-Union{Tuple{MLUtils.DataLoader}, Tuple{scen}} where scen","page":"Home","title":"HybridVariationalInference.gdev_hybridproblem_dataloader","text":"gdev_hybridproblem_dataloader(dataloader::MLUtils.DataLoader,\n    scenario = (), \n    gdev = gpu_device(),\n    gdev_M = :use_gpu ∈ scenario ? gdev : identity,\n    gdev_P = :f_on_gpu ∈ scenario ? gdev : identity,\n    batchsize = dataloader.batchsize,\n    partial = dataloader.partial\n    )\n\nPut relevant parts of the DataLoader to gpu, depending on scenario.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.gen_cov_pred-Tuple{Random.AbstractRNG, DataType, Any, Any, Any, Integer}","page":"Home","title":"HybridVariationalInference.gen_cov_pred","text":"Generate correlated covariates and synthetic true parameters that are a linear combination of the uncorrelated underlying principal  factors and their binary combinations.\n\nIn addition provide a SimpleChains model of adequate complexity to fit this relationship θMstrue = f(xo)\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.gen_hybridproblem_synthetic","page":"Home","title":"HybridVariationalInference.gen_hybridproblem_synthetic","text":"gen_hybridproblem_synthetic([rng,] ::AbstractHybridProblem; scenario)\n\nSetup synthetic data, a NamedTuple of\n\nxM: matrix of covariates, with one column per site\nθP_true: vector global process-model parameters\nθMs_true: matrix of site-varying process-model parameters, with \nxP: Vector of process-model drivers, with an entry per site\nyglobaltrue: vector of global observations\ny_true: matrix of site-specific observations with one column per site\nyglobalo, y_o: observations with added noise\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.generate_ζ-Union{Tuple{MT}, Tuple{FT}, Tuple{Any, Any, AbstractVector{FT}, MT}} where {FT, MT}","page":"Home","title":"HybridVariationalInference.generate_ζ","text":"Generate samples of (inv-transformed) model parameters, ζ,  and the vector of standard deviations, σ, i.e. the diagonal of the cholesky-factor.\n\nAdds the MV-normally distributed residuals, retrieved by sample_ζresid_norm to the means extracted from parameters and predicted by the machine learning model. \n\nThe output shape of size (n_site x n_par x n_MC) is tailored to iterating each MC sample and then transforming each parameter on block across sites.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_ca_ends-Tuple{ComponentArrays.ComponentVector}","page":"Home","title":"HybridVariationalInference.get_ca_ends","text":"get_ca_ends(vc::ComponentVector)\n\nReturn a Vector with ending positions of components in vc.  Useful for providing information on correlactions among subranges in a vector.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_ca_starts-Tuple{ComponentArrays.ComponentVector}","page":"Home","title":"HybridVariationalInference.get_ca_starts","text":"get_ca_starts(vc::ComponentVector)\n\nReturn a tuple with starting positions of components in vc.  Useful for providing information on correlactions among subranges in a vector.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_cor_count-Tuple{AbstractVector}","page":"Home","title":"HybridVariationalInference.get_cor_count","text":"get_cor_count(cor_ends::AbstractVector)\nget_cor_count(n_par::Integer)\n\nReturn number of correlation coefficients for a correlation matrix of size (npar x npar) With blocks starting a positions given with tuple cor_ends.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridproblem_MLapplicator","page":"Home","title":"HybridVariationalInference.get_hybridproblem_MLapplicator","text":"get_hybridproblem_MLapplicator([rng::AbstractRNG,] ::AbstractHybridProblem; scenario=())\n\nConstruct the machine learning model fro given problem prob and ML-Framework and  scenario.\n\nreturns a Tuple of\n\nAbstractModelApplicator\ninitial parameter vector\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridproblem_PBmodel","page":"Home","title":"HybridVariationalInference.get_hybridproblem_PBmodel","text":"get_hybridproblem_PBmodel(::AbstractHybridProblem; scenario::NTuple=())\n\nConstruct the process-based model function  f(θP::AbstractVector, θMs::AbstractMatrix, x) -> (AbstractVector, AbstractMatrix) with\n\nθP: calibrated parameters that are constant across site\nθMs: calibrated parameters that vary across sites, with a  column for each site\nx: drivers, indexed by site\n\nreturns a tuple of predictions with components\n\nfirst, those that are constant across sites\nsecond, those that vary across sites, with a column for each site\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridproblem_cor_ends-Tuple{AbstractHybridProblem}","page":"Home","title":"HybridVariationalInference.get_hybridproblem_cor_ends","text":"get_hybridproblem_cor_ends(prob::AbstractHybridProblem; scenario)\n\nSpecify blocks in correlation matrices among parameters. Returns a NamedTuple.\n\nP: correlations among global parameters\nM: correlations among ML-predicted parameters\n\nSubsets ofparameters that are correlated with other but not correlated with parameters of other subranges are specified by indicating the starting position of each subrange. E.g. if within global parameter vector (p1, p2, p3), p1 and p2 are correlated,  but parameter p3 is not correlated with them, then the first subrange starts at position 1 and the second subrange starts at position 3. If there is only single block of all ML-predicted parameters being correlated  with each other then this block starts at position 1: (P=(1,3), M=(1,)).\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridproblem_float_type-Tuple{AbstractHybridProblem}","page":"Home","title":"HybridVariationalInference.get_hybridproblem_float_type","text":"get_hybridproblem_float_type(::AbstractHybridProblem; scenario)\n\nDetermine the FloatType for given Case and scenario, defaults to Float32\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridproblem_n_covar-Tuple{AbstractHybridProblem}","page":"Home","title":"HybridVariationalInference.get_hybridproblem_n_covar","text":"get_hybridproblem_n_covar(::AbstractHybridProblem; scenario)\n\nProvide the number of covariates. \n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridproblem_n_site_and_batch","page":"Home","title":"HybridVariationalInference.get_hybridproblem_n_site_and_batch","text":"get_hybridproblem_n_site_and_batch(::AbstractHybridProblem; scenario)\n\nProvide the number of sites. \n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridproblem_neg_logden_obs","page":"Home","title":"HybridVariationalInference.get_hybridproblem_neg_logden_obs","text":"get_hybridproblem_neg_logden_obs(::AbstractHybridProblem; scenario)\n\nProvide a function(y_obs, ypred) -> Real that computes the negative logdensity of the observations, given the predictions.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridproblem_par_templates","page":"Home","title":"HybridVariationalInference.get_hybridproblem_par_templates","text":"get_hybridproblem_par_templates(::AbstractHybridProblem; scenario)\n\nProvide tuple of templates of ComponentVectors θP and θM.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridproblem_priors-Tuple{AbstractHybridProblem}","page":"Home","title":"HybridVariationalInference.get_hybridproblem_priors","text":"get_hybridproblem_priors(::AbstractHybridProblem; scenario)\n\nReturn a dictionary of marginal prior distributions for components in θP and θM. Defaults for each component θ to Normal(θ, max(θ, 1.0)).\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_hybridproblem_train_dataloader","page":"Home","title":"HybridVariationalInference.get_hybridproblem_train_dataloader","text":"get_hybridproblem_train_dataloader(::AbstractHybridProblem; scenario, n_batch)\n\nReturn a DataLoader that provides a tuple of\n\nxM: matrix of covariates, with one column per site\nxP: Iterator of process-model drivers, with one element per site\ny_o: matrix of observations with added noise, with one column per site\ny_unc: matrix sizeof(y_o) of uncertainty information \ni_sites: Vector of indices of sites in toal sitevector for the minibatch\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridproblem_transforms","page":"Home","title":"HybridVariationalInference.get_hybridproblem_transforms","text":"get_hybridproblem_transforms(::AbstractHybridProblem; scenario)\n\nReturn a NamedTupe of\n\ntransP: Bijectors.Transform for the global PBM parameters, θP\ntransM: Bijectors.Transform for the single-site PBM parameters, θM\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_hybridproblem_ϕunc-Tuple{AbstractHybridProblem}","page":"Home","title":"HybridVariationalInference.get_hybridproblem_ϕunc","text":"get_hybridproblem_ϕunc(::AbstractHybridProblem; scenario)\n\nProvide a ComponentArray of the initial additional parameters of the approximate posterior. Defaults to zero correlation and log_σ2 of 1e-10.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_loss_elbo-NTuple{6, Any}","page":"Home","title":"HybridVariationalInference.get_loss_elbo","text":"Create a loss function for parameter vector ϕ, given \n\ng(x, ϕ): machine learning model \ntransPMS: transformation from unconstrained space to parameter space\nf(θMs, θP): mechanistic model \ninterpreters: assigning structure to pure vectors, see neg_elbo_gtf\nn_MC: number of Monte-Carlo sample to approximate the expected value across distribution\npbm_covars: tuple of symbols of process-based parameters provided to the ML model\nθP: ComponentVector as a template to select indices of pbm_covars\n\nThe loss function takes in addition to ϕ, data that changes with minibatch\n\nrng: random generator\nxM: matrix of covariates, sites in columns\nxP: drivers for the processmodel: Iterator of size n_site\ny_o, y_unc: matrix of observations and uncertainties, sites in columns\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_loss_gf","page":"Home","title":"HybridVariationalInference.get_loss_gf","text":"Create a loss function for given\n\ng(x, ϕ): machine learning model \ntransM: transforamtion of parameters at unconstrained space\nf(θMs, θP): mechanistic model \nyoglobal: site-independent observations\nintϕ: interpreter attaching axis with components ϕg and ϕP\nintP: interpreter attaching axis to ζP = ϕP with components used by f\nkwargs: additional keyword arguments passed to gf, such as gdev or pbm_covars\n\nThe loss function loss_gf(ϕ, xM, xP, y_o, y_unc, i_sites) takes   \n\nparameter vector ϕ\nxM: matrix of covariate, sites in the batch are in columns\nxP: iteration of drivers for each site\ny_o: matrix of observations, sites in columns\ny_unc: vector of uncertainty information for each observation\ni_sites: index of sites in the batch\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.get_positions-Tuple{AbstractComponentArrayInterpreter}","page":"Home","title":"HybridVariationalInference.get_positions","text":"get_positions(cai::AbstractComponentArrayInterpreter)\n\nCreate a NamedTuple of integer indices for each component. Assumes that interpreter results in a one-dimensional array, i.e. in a ComponentVector.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.get_quantile_transformed-Tuple{AbstractVector{<:Distributions.Distribution}, Any}","page":"Home","title":"HybridVariationalInference.get_quantile_transformed","text":"Get the inverse-transformation of lower and upper quantiles of a Vector of Distributions.\n\nThis can be used to get proper confidence intervals at unconstrained (log) ζ-scale for priors on normal θ-scale for constructing a NormalScalingModelApplicator.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.gf-Tuple{AbstractHybridProblem}","page":"Home","title":"HybridVariationalInference.gf","text":"composition f ∘ transM ∘ g: mechanistic model after machine learning parameter prediction\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.gtrans-NTuple{4, Any}","page":"Home","title":"HybridVariationalInference.gtrans","text":"composition transM ∘ g: transformation after machine learning parameter prediction Provide a transMs = StackedArray(transM, n_batch)\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.init_hybrid_params-Union{Tuple{FT}, Tuple{AbstractVector{FT}, AbstractVector{FT}, NamedTuple, AbstractVector{FT}, HybridProblemInterpreters}} where FT","page":"Home","title":"HybridVariationalInference.init_hybrid_params","text":"init_hybrid_params(θP, θM, ϕg, n_batch; transP=asℝ, transM=asℝ)\n\nSetup ComponentVector of parameters to optimize, and associated tools. Returns a NamedTuple of\n\nϕ: A ComponentVector of parameters to optimize\ntransPMsbatch, interpreters: Transformations and interpreters as  required by `negelbo_gtf`.\ngettransPMs: a function returning transformations `(nsite) -> (;P,Ms)`\ngetcaintPMs: a function returning ComponentArrayInterpreter for PMs vector  with PMs shaped as a matrix of `nsitecolumns ofθM`\n\nArguments\n\nθP, θM: Template ComponentVectors of global parameters and ML-predicted parameters\ncor_ends: NamedTuple with entries, P, and M, respectively with   integer vectors of ending columns of parameters blocks\nϕg: vector of parameters to optimize, as returned by get_hybridproblem_MLapplicator\nn_batch: the number of sites to predicted in each mini-batch\ntransP, transM: the Bijector.Transformations for the global and site-dependent    parameters, e.g. Stacked(elementwise(identity), elementwise(exp), elementwise(exp)).   Its the transformation froing from unconstrained to constrained space: θ = Tinv(ζ),   because this direction is used much more often.\nϕunc0 initial uncertainty parameters, ComponentVector with format of init_hybrid_ϕunc.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.init_hybrid_ϕunc-Union{Tuple{NamedTuple}, Tuple{FT}, Tuple{NamedTuple, FT}, Tuple{NamedTuple, FT, AbstractVector{FT}}} where FT","page":"Home","title":"HybridVariationalInference.init_hybrid_ϕunc","text":"init_hybrid_ϕunc(cor_ends, ρ0=0f0; logσ2_ζP, coef_logσ2_ζMs, ρsP, ρsM)\n\nInitialize vector of additional parameter of the approximate posterior.\n\nArguments:\n\ncor_ends: NamedTuple with entries, P, and M, respectively with   integer vectors of ending columns of parameters blocks\nρ0: default entry for ρsP and ρsM, defaults = 0f0.\ncoef_logσ2_logM: default column for coef_logσ2_ζMs, defaults to [-10.0, 0.0]\n\nReturns a ComponentVector of \n\nlogσ2_ζP: vector of log-variances of ζP (on log scale). defaults to -10\ncoef_logσ2_ζMs: offset and slope for the log-variances of ζM scaling with   its value given by columns for each parameter in ζM, defaults to [-10, 0]\nρsP and ρsM: parameterization of the upper triangular cholesky factor  of the correlation matrices of ζP and ζM, default to all entries ρ0, which defaults to zero.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.invsumn-Tuple{T} where T","page":"Home","title":"HybridVariationalInference.invsumn","text":"Inverse of s = sumn(n) for positive integer n.\n\nGives an inexact error, if given s was not such a sum.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.map_f_each_site-Tuple{Any, AbstractMatrix, AbstractVector, AbstractVector, Any, Vararg{Any}}","page":"Home","title":"HybridVariationalInference.map_f_each_site","text":"Map process base model (PBM), f, across each site.\n\nArguments\n\nf(θ, xP, args...; intθ1, kwargs...): Process based model for single site\nMake sure to hint the type, so that results can be inferred.\nθMst: transposed model parameters across sites matrix: (nparM, nsite_batch)\nθP: transposed model parameters that do not differ by site: (n_parP,)\nθFix: Further parameter required by f that are not calibrated.\nxP: Model drivers: Matrix with nsitebatch columns. If provided a ComponentArray with labeled rows, f can then access xP[:key].\nintθ1: ComponentArrayInterpreter that can be applied to θ,  so that entries can be extracted.\n\nSee test_HybridProblem of using this function to construct a PBM function that can predict across all sites.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.neg_elbo_gtf-Tuple","page":"Home","title":"HybridVariationalInference.neg_elbo_gtf","text":"Cost function (ELBO) for hybrid model with batched sites.\n\nIt generates n_MC samples for each site, and uses these to compute the expected value of the likelihood of observations.\n\nArguments\n\nrng: random number generator (ignored on CUDA, if ϕ is a AbstractGPUArray)\nϕ: flat vector of parameters interpreted by interpreters.μPϕgunc and interpreters.PMs\ng: machine learning model\ntransPMs: Transformations as generated by gettransPMs returned from inithybrid_params\nf: mechanistic model\npy: negative log-likelihood of observations given predictions:  function(y_ob, y_pred, y_unc)\nxM, xP, y_ob, y_unc, i_sites: information of the sites in the current minibatch\nxM: matrix of covariates (ncov x nsite_batch)\nxP: model drivers, iterable of (nsitebatch)\ny_ob: matrix of observations (nobs x nsite_batch)\ny_unc: observation uncertainty provided to py (same size as y_ob)\ni_sites: indices of sites for current minibatch\ninterpreters: NamedTuple as generated by gen_hybridproblem_synthetic with entries:\nμP_ϕg_unc: extract components of parameter of \nmeans of global PBM, 2) ML-weights, and 3) additional parameters of approximation q\nPMs: assign components to PBM parameters 1 global, 2 matrix of n_site column  vectors\nint_unc (can be omitted, if μP_ϕg_unc(ϕ).unc is already a ComponentVector)\nn_MC: number of MonteCarlo samples from the distribution of parameters to simulate using the mechanistic model f.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.neg_elbo_ζtf-NTuple{8, Any}","page":"Home","title":"HybridVariationalInference.neg_elbo_ζtf","text":"Compute the neg_elbo for each sampled parameter vector (last dimension of ζs).\n\nTransform and compute log-jac\ncall forward model\ncompute log-density of predictions\ncompute entropy of transformation\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.neg_logden_indep_normal-Union{Tuple{ET}, Tuple{AbstractArray, AbstractArray, AbstractArray{ET}}} where ET","page":"Home","title":"HybridVariationalInference.neg_logden_indep_normal","text":"neg_logden_indep_normal(obs, μ, logσ2s; σfac=1.0)\n\nCompute the negative Log-density of θM for multiple independent normal distributions, given estimated means μ and estimated log of variance parameters logσ2s.\n\nAll the arguments should be vectors of the same length. If obs,  μ are given as a matrix of several column-vectors, their summed Likelihood is computed, assuming each column having the same logσ2s.\n\nKeyword argument σfac can be increased to put more weight on achieving a low uncertainty estimate and means closer to the observations to help an initial fit. The obtained parameters then can be used as starting values for a the proper fit with σfac=1.0.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.predict_hvi-Tuple{Any, AbstractHybridProblem}","page":"Home","title":"HybridVariationalInference.predict_hvi","text":"predict_hvi([rng], prob::AbstractHybridProblem [,xM, xP]; scenario, ...)\npredict_hvi(rng, g, f, ϕ::AbstractVector, xM::AbstractMatrix;\n    get_transPMs, get_ca_int_PMs, n_sample_pred=200, gdev = identity)\n\nPrediction function for hybrid variational inference parameter model. \n\nArguments\n\nThe problem for which to predict\nxM: covariates for the machine-learning model (ML): Matrix (nθM x nsite_pred).\nxP: model drivers for process based model (PBM): Matrix with (nsitepred) rows. If provided a ComponentArray with a Tuple-Axis in rows, the PBM model can access parts of it, e.g. xP[:S1,...].\n\nKeyword arguments\n\nscenario\nnsamplepred\n\nReturns an NamedTuple (; y, θsP, θsMs, entropy_ζ) with entries\n\ny: Array (n_obs, n_site, n_sample_pred) of model predictions.\nθsP: ComponentArray (n_θP, n_sample_pred) of PBM model parameters that are kept constant across sites.\nθsMs: ComponentArray (n_site, n_θM, n_sample_pred) of PBM model parameters that vary by site.\nentropy_ζ: The entropy of the log-determinant of the transformation of  the set of model parameters, which is involved in uncertainty quantification.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.sample_ζresid_norm-Tuple{Random.AbstractRNG, AbstractVector, AbstractMatrix, Vararg{Any}}","page":"Home","title":"HybridVariationalInference.sample_ζresid_norm","text":"Extract relevant parameters from ζ and return nMC generated multivariate normal draws together with the vector of standard deviations, σ: `(ζPresids, ζMsparfirstresids, σ)The output shape(nθ, nsite?, nMC)is tailored to addingζMsparfirstresidsto ML-model predcitions of size(nθM, n_site)`.\n\nArguments\n\nint_unc: Interpret vector as ComponentVector with components  ρsP, ρsM, logσ2ζP, coeflogσ2_ζMs(intercept + slope), \n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.scale_centered_at","page":"Home","title":"HybridVariationalInference.scale_centered_at","text":"scale_centered_at(x, m, σrel=1.0)\nscale_centered_at(x, m, σ)\n\nCenters and rescales rows of matrix x around vector m. The scale can either be given relative to m or specified as a vector of same size as m.\n\n\n\n\n\n","category":"function"},{"location":"#HybridVariationalInference.select_ml_engine-Union{Tuple{}, Tuple{scen}} where scen","page":"Home","title":"HybridVariationalInference.select_ml_engine","text":"select_ml_engine(;scenario)\n\nReturns a value type Val{:Symbol} to dispatch on the machine learning engine to use.\n\ndefaults to Val(:SimpleChains)\n:use_Lux ∈ scenario -> Val(:Lux)\n:use_Flux ∈ scenario -> Val(:Flux)\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.stack_ca_int-Union{Tuple{n_dims}, Tuple{IT}, Tuple{IT, Val{n_dims}}} where {IT<:AbstractComponentArrayInterpreter, n_dims}","page":"Home","title":"HybridVariationalInference.stack_ca_int","text":"stack_ca_int(cai::AbstractComponentArrayInterpreter, ::Val{n_dims})\n\nInterpret the first dimension of an Array as a ComponentArray. Provide the Tuple of following dimensions by a value type, e.g. Val((n_col, n_z)).\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.transformU_block_cholesky1-Union{Tuple{AbstractVector{T}}, Tuple{TI}, Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{TI}}} where {T, TI<:Integer}","page":"Home","title":"HybridVariationalInference.transformU_block_cholesky1","text":"transformU_block_cholesky1(v::AbstractVector, cor_ends)\n\nTransform a parameterization v of a blockdiagonal of upper triangular matrices into the this matrix. cor_ends is an AbstractVector of Integers specifying the last column of each block.  E.g. For a matrix with a 3x3, a 2x2, and another single-entry block,  the blocks start at columns (3,5,6). It defaults to a single entire block.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.transformU_cholesky1-Tuple{AbstractVector}","page":"Home","title":"HybridVariationalInference.transformU_cholesky1","text":"Takes a vector of entries of a lower UnitUpperTriangular matrix and transforms it to an UpperTriangular that satisfies  diag(U' * U) = 1.\n\nThis can be used to fit parameters that yield an upper Cholesky-Factor of a Covariance matrix.\n\nIt uses the upper triangular matrix rather than the lower because it involes a sum across columns, whereas the alternative of a lower triangular uses sum across rows.  Sum across columns is often faster, because entries of columns are contiguous.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.transform_ζs-Tuple{AbstractMatrix, AbstractArray}","page":"Home","title":"HybridVariationalInference.transform_ζs","text":"Transform parameters \n\nfrom unconstrained (e.g. log) ζ scale of format ((nsite x npar) x n_mc)\nto constrained θ scale of the same format\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.transpose_mPMs_sitefirst-Tuple{Any, Integer, Any, Any, Any}","page":"Home","title":"HybridVariationalInference.transpose_mPMs_sitefirst","text":"Transforms each row of a matrix (nMC x nPar) with site parameters Ms inside nPar  of form (npar x nsite) to Ms of the form (nsite x n_par), i.e.  neighboring entries (inside a column) are of the same parameter.\n\nThis format of having n_par as the last dimension helps transforming parameters on block.\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.utri2vec-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T","page":"Home","title":"HybridVariationalInference.utri2vec","text":"Extract entries of upper diagonal matrix of UppterTriangular to columnwise vector\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.utri2vec_pos-Tuple{Any, Any}","page":"Home","title":"HybridVariationalInference.utri2vec_pos","text":"Compute the index in the vector of entries in an upper tridiagonal matrix\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.uutri2vec-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T","page":"Home","title":"HybridVariationalInference.uutri2vec","text":"Extract entries of upper diagonal matrix of UnitUppterTriangular to columnwise vector\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.vec2utri-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T","page":"Home","title":"HybridVariationalInference.vec2utri","text":"Convert vector v columnwise entries of upper diagonal matrix to UppterTriangular\n\n\n\n\n\n","category":"method"},{"location":"#HybridVariationalInference.vec2utri_pos-Tuple{Any, Any}","page":"Home","title":"HybridVariationalInference.vec2utri_pos","text":"Compute the (one-based) position (row, col) within an upper tridiagonal matrix for given (one-based) position, s within a packed vector representation.\n\n\n\n\n\n","category":"method"}]
}
