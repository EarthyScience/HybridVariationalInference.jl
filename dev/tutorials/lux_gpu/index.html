<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>.. use GPU · HybridVariationalInference.jl</title><meta name="title" content=".. use GPU · HybridVariationalInference.jl"/><meta property="og:title" content=".. use GPU · HybridVariationalInference.jl"/><meta property="twitter:title" content=".. use GPU · HybridVariationalInference.jl"/><meta name="description" content="Documentation for HybridVariationalInference.jl."/><meta property="og:description" content="Documentation for HybridVariationalInference.jl."/><meta property="twitter:description" content="Documentation for HybridVariationalInference.jl."/><meta property="og:url" content="https://EarthyScience.github.io/HybridVariationalInference.jl/tutorials/lux_gpu/"/><meta property="twitter:url" content="https://EarthyScience.github.io/HybridVariationalInference.jl/tutorials/lux_gpu/"/><link rel="canonical" href="https://EarthyScience.github.io/HybridVariationalInference.jl/tutorials/lux_gpu/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">HybridVariationalInference.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../problem/">Problem</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../basic_cpu/">Basic workflow</a></li><li><a class="tocitem" href="../inspect_results/">Inspect results</a></li></ul></li><li><span class="tocitem">How to</span><ul><li class="is-active"><a class="tocitem" href>.. use GPU</a><ul class="internal"><li><a class="tocitem" href="#Motivation"><span>Motivation</span></a></li><li><a class="tocitem" href="#Updating-the-ML-model-of-the-problem-to-use-LUX"><span>Updating the ML model of the problem to use LUX</span></a></li><li><a class="tocitem" href="#Specifying-GPU-devices-during-solve"><span>Specifying GPU devices during solve</span></a></li><li><a class="tocitem" href="#Moving-results-from-GPU-to-CPU"><span>Moving results from GPU to CPU</span></a></li></ul></li><li><a class="tocitem" href="../blocks_corr/">.. model independent parameters</a></li><li><a class="tocitem" href="../corr_site_global/">.. model site-global corr</a></li></ul></li><li><span class="tocitem">Explanation</span></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../../reference/reference_public/">Public</a></li><li><a class="tocitem" href="../../reference/reference_internal/">Internal</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How to</a></li><li class="is-active"><a href>.. use GPU</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>.. use GPU</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/EarthyScience/HybridVariationalInference.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/EarthyScience/HybridVariationalInference.jl/blob/main/docs/src/tutorials/lux_gpu.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="How-to-move-computations-to-GPU"><a class="docs-heading-anchor" href="#How-to-move-computations-to-GPU">How to move computations to GPU</a><a id="How-to-move-computations-to-GPU-1"></a><a class="docs-heading-anchor-permalink" href="#How-to-move-computations-to-GPU" title="Permalink"></a></h1><p>This guide shows how to configure the setup and inversion of a HybridProblem so that computations of the ML model and maybe also the process-based model are executed on GPU.</p><h2 id="Motivation"><a class="docs-heading-anchor" href="#Motivation">Motivation</a><a id="Motivation-1"></a><a class="docs-heading-anchor-permalink" href="#Motivation" title="Permalink"></a></h2><p>Machine learning is often accelerated by moving computations form CPU to GPU. So does HVI.</p><p>First load necessary packages.</p><pre><code class="language-julia hljs">using HybridVariationalInference
using ComponentArrays: ComponentArrays as CA
using Bijectors
using Lux
using SimpleChains # only loading save object
using StatsFuns
using StableRNGs
using MLUtils
using JLD2
using Random
using MLDataDevices
# using CairoMakie
# using PairPlots   # scatterplot matrices</code></pre><p>This tutorial reuses and modifies the fitted object saved at the end of the <a href="../basic_cpu/#Basic-workflow-without-GPU">Basic workflow without GPU</a> tutorial.</p><pre><code class="language-julia hljs">fname = &quot;intermediate/basic_cpu_results.jld2&quot;
print(abspath(fname))
prob = probo_chain = load(fname, &quot;probo&quot;);</code></pre><h2 id="Updating-the-ML-model-of-the-problem-to-use-LUX"><a class="docs-heading-anchor" href="#Updating-the-ML-model-of-the-problem-to-use-LUX">Updating the ML model of the problem to use LUX</a><a id="Updating-the-ML-model-of-the-problem-to-use-LUX-1"></a><a class="docs-heading-anchor-permalink" href="#Updating-the-ML-model-of-the-problem-to-use-LUX" title="Permalink"></a></h2><p>Because the SimpleChains ML model used in the basic tutorial does not support GPU, we reconstruct the model using the LUX framework. Note that all the setup is almost the same, as in the basic workflow. The only difference is that a <code>Lux.Chains</code> object is provided to <code>construct_ChainsApplicator</code>.</p><pre><code class="language-julia hljs">n_out = length(prob.θM) # number of individuals to predict 
n_covar = 5 #size(xM,1)
n_input = n_covar 

g_lux = Lux.Chain(
    Lux.Dense(n_covar =&gt; n_covar * 4, tanh),
    Lux.Dense(n_covar * 4 =&gt; n_covar * 4, tanh),
    Lux.Dense(n_covar * 4 =&gt; n_out, logistic, use_bias = false)
)
# get a template of the parameter vector, ϕg0
rng = StableRNG(111)
g_chain_app, ϕg0 = construct_ChainsApplicator(rng, g_lux)
#
priorsM = [prob.priors[k] for k in keys(prob.θM)]
lowers, uppers = get_quantile_transformed(priorsM, prob.transM)
FT = eltype(prob.θM)
g_chain_scaled = NormalScalingModelApplicator(g_chain_app, lowers, uppers, FT)</code></pre><p>Update the <code>HybridProblem</code> to use this ML model.</p><pre><code class="language-julia hljs">prob_lux = HybridProblem(probo_chain; g=g_chain_scaled, ϕg=ϕg0)</code></pre><h2 id="Specifying-GPU-devices-during-solve"><a class="docs-heading-anchor" href="#Specifying-GPU-devices-during-solve">Specifying GPU devices during solve</a><a id="Specifying-GPU-devices-during-solve-1"></a><a class="docs-heading-anchor-permalink" href="#Specifying-GPU-devices-during-solve" title="Permalink"></a></h2><p>The <a href="../../reference/reference_internal/#CommonSolve.solve-Union{Tuple{is_infer}, Tuple{scen}, Tuple{AbstractHybridProblem, HybridPosteriorSolver}} where {scen, is_infer}"><code>solve</code></a> method for the HybridPosteriorSolver accepts argument <code>gdevs</code>, Its a <code>NamedTuple</code> with entries<code>gdev_M</code> and <code>gdev_P</code>, for the ML model on and the process-basee model (PBM) respectively. They specify functions that are applied to move callables and data to GPU.</p><p>They default to <code>identity</code>, meaning that nothing is moved from CPU to GPU. Function <code>gpu_device()</code> from package <code>MLDataDevices</code> can be used instead for the standard GPU device.</p><p>Hence specify</p><ul><li><code>gdevs = (; gdev_M=gpu_device(), gdev_P=gpu_device())</code>: to move both ML model and PBM to GPU</li><li><code>gdevs = (; gdev_M=gpu_device(), gdev_P=identity)</code>: to move both ML model to GPU but execute the PBM (and parameter transformation) on CPU</li></ul><p>Currently, putting the PBM on gpu is not efficient during inversion, because prior distribution needs to be evaluated for each sample. However, sampling and prediction using a fitted model is efficient.</p><p>In addition, the libraries of the GPU device need to be activated by importing respective Julia packages. Currently, only CUDA is tested with this <code>HybridVariationalInference</code> package.</p><pre><code class="language-julia hljs">import CUDA, cuDNN # so that gpu_device() returns a CUDADevice

using OptimizationOptimisers
import Zygote
solver = HybridPosteriorSolver(; alg=Adam(0.02), n_MC=3)

(; probo) = solve(prob_lux, solver; 
    callback = callback_loss(100), 
    epochs = 10,
    gdevs = (; gdev_M=gpu_device(), gdev_P=identity)
); probo_lux = probo;</code></pre><h2 id="Moving-results-from-GPU-to-CPU"><a class="docs-heading-anchor" href="#Moving-results-from-GPU-to-CPU">Moving results from GPU to CPU</a><a id="Moving-results-from-GPU-to-CPU-1"></a><a class="docs-heading-anchor-permalink" href="#Moving-results-from-GPU-to-CPU" title="Permalink"></a></h2><p>The sampling and prediction methods, also take this <code>gdevs</code> keyword argument.</p><pre><code class="language-julia hljs">n_sample_pred = 400
(y_dev, θsP_dev, θsMs_dev) = (; y, θsP, θsMs) = predict_hvi(
  rng, probo_lux; n_sample_pred, 
  gdevs = (; gdev_M=gpu_device(), gdev_P=gpu_device()));</code></pre><p>If <code>gdev_P</code> is not an <code>AbstractGPUDevice</code> then all the results are on CPU. If <code>gdev_P</code> is an <code>AbstractGPUDevice</code> then the results are GPUArrays and need to be transferred to CPU.</p><pre><code class="language-julia hljs">typeof(θsMs_dev)</code></pre><pre><code class="nohighlight hljs">ComponentArrays.ComponentArray{Float32, 3, CUDA.CuArray{Float32, 3, CUDA.DeviceMemory}, Tuple{ComponentArrays.Axis{(i = 1:800,)}, ComponentArrays.Axis{(r1 = 1, K1 = 2)}, ComponentArrays.Axis{(i = 1:400,)}}}</code></pre><p>Handling of a <code>ComponentArrays</code> backed by GPUArrays can result in errors of scalar indexing. Therefore, use a semicolon to suppress printing. Also for moving the <code>ComponentArrays</code> to CPU, use function <a href="../../reference/reference_public/#HybridVariationalInference.apply_preserve_axes-Tuple{Any, ComponentArrays.ComponentArray}"><code>apply_preserve_axes</code></a> to circumvent this error.</p><pre><code class="language-julia hljs">cdev = cpu_device()
y = cdev(y_dev)
θsP = apply_preserve_axes(cdev, θsP_dev)
θsMs = apply_preserve_axes(cdev, θsMs_dev)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../inspect_results/">« Inspect results</a><a class="docs-footer-nextpage" href="../blocks_corr/">.. model independent parameters »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Saturday 23 August 2025 16:17">Saturday 23 August 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
