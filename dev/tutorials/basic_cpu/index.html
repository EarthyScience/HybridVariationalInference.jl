<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Basic workflow · HybridVariationalInference.jl</title><meta name="title" content="Basic workflow · HybridVariationalInference.jl"/><meta property="og:title" content="Basic workflow · HybridVariationalInference.jl"/><meta property="twitter:title" content="Basic workflow · HybridVariationalInference.jl"/><meta name="description" content="Documentation for HybridVariationalInference.jl."/><meta property="og:description" content="Documentation for HybridVariationalInference.jl."/><meta property="twitter:description" content="Documentation for HybridVariationalInference.jl."/><meta property="og:url" content="https://EarthyScience.github.io/HybridVariationalInference.jl/tutorials/basic_cpu/"/><meta property="twitter:url" content="https://EarthyScience.github.io/HybridVariationalInference.jl/tutorials/basic_cpu/"/><link rel="canonical" href="https://EarthyScience.github.io/HybridVariationalInference.jl/tutorials/basic_cpu/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">HybridVariationalInference.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../problem/">Problem</a></li><li><span class="tocitem">Tutorials</span><ul><li class="is-active"><a class="tocitem" href>Basic workflow</a><ul class="internal"><li><a class="tocitem" href="#The-process-based-model"><span>The process-based model</span></a></li><li><a class="tocitem" href="#Likelihood-function"><span>Likelihood function</span></a></li><li><a class="tocitem" href="#Global-Site,-transformations,-and-priors"><span>Global-Site, transformations, and priors</span></a></li><li><a class="tocitem" href="#Observations,-model-drivers-and-covariates"><span>Observations, model drivers and covariates</span></a></li><li><a class="tocitem" href="#The-Machine-Learning-model"><span>The Machine-Learning model</span></a></li><li><a class="tocitem" href="#Assembling-the-information"><span>Assembling the information</span></a></li><li><a class="tocitem" href="#Perform-the-inversion"><span>Perform the inversion</span></a></li><li><a class="tocitem" href="#Using-a-population-level-process-based-model"><span>Using a population-level process-based model</span></a></li><li><a class="tocitem" href="#Saving-the-results"><span>Saving the results</span></a></li></ul></li><li><a class="tocitem" href="../inspect_results/">Inspect results</a></li></ul></li><li><span class="tocitem">How to</span><ul><li><a class="tocitem" href="../lux_gpu/">.. use GPU</a></li><li><a class="tocitem" href="../logden_user/">.. specify log-Likelihood</a></li><li><a class="tocitem" href="../blocks_corr/">.. model independent parameters</a></li><li><a class="tocitem" href="../corr_site_global/">.. model site-global corr</a></li></ul></li><li><span class="tocitem">Explanation</span></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../../reference/reference_public/">Public</a></li><li><a class="tocitem" href="../../reference/reference_internal/">Internal</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Basic workflow</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Basic workflow</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/EarthyScience/HybridVariationalInference.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/EarthyScience/HybridVariationalInference.jl/blob/main/docs/src/tutorials/basic_cpu.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Basic-workflow-without-GPU"><a class="docs-heading-anchor" href="#Basic-workflow-without-GPU">Basic workflow without GPU</a><a id="Basic-workflow-without-GPU-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-workflow-without-GPU" title="Permalink"></a></h1><p>First load necessary packages.</p><pre><code class="language-julia hljs">using HybridVariationalInference
using HybridVariationalInference: HybridVariationalInference as HVI
using ComponentArrays: ComponentArrays as CA
using Bijectors
using StableRNGs
using SimpleChains
using StatsFuns
using MLUtils
using DistributionFits
using UnPack</code></pre><p>Next, specify many moving parts of the Hybrid variational inference (HVI)</p><h2 id="The-process-based-model"><a class="docs-heading-anchor" href="#The-process-based-model">The process-based model</a><a id="The-process-based-model-1"></a><a class="docs-heading-anchor-permalink" href="#The-process-based-model" title="Permalink"></a></h2><p>The example process based model (PBM) predicts a double-monod constrained rate for different substrate concentrations, <code>S1</code>, and <code>S2</code>.</p><p>$</p><p>y = r<em>0+ r</em>1 \frac{S<em>1}{K</em>1 + S<em>1} \frac{S</em>2}{K<em>2 + S</em>2} $</p><pre><code class="language-julia hljs">function f_doubleMM(θc::CA.ComponentVector{ET}, x) where ET
    # extract parameters not depending on order, i.e whether they are in θP or θM
    @unpack r0, r1, K1, K2 = θc
    r0 .+ r1 .* x.S1 ./ (K1 .+ x.S1) .* x.S2 ./ (K2 .+ x.S2)
end</code></pre><p>Its formulation is independent of which parameters are global, site-specific, or fixed during the model inversion. However, it cannot assume an ordering in the parameters, but needs to access the components by its symbolic names in the provided <code>ComponentArray</code>.</p><h2 id="Likelihood-function"><a class="docs-heading-anchor" href="#Likelihood-function">Likelihood function</a><a id="Likelihood-function-1"></a><a class="docs-heading-anchor-permalink" href="#Likelihood-function" title="Permalink"></a></h2><p>HVI requires the evaluation of the likelihood of the predictions. It corresponds to the cost of predictions given some observations.</p><p>The user specifies a function of the negative log-Likelihood <code>neg_logden(obs, pred, uncertainty_parameters)</code>, where all of the parameters are arrays with columns for sites.</p><p>Here, we use the <a href="../../reference/reference_public/#HybridVariationalInference.neg_logden_indep_normal-Union{Tuple{ET}, Tuple{AbstractArray, AbstractArray, AbstractArray{ET}}} where ET"><code>neg_logden_indep_normal</code></a> function that assumed observations to be distributed independently normal around a true value. The provided <code>y_unc</code> uncertainty parameters, here, corresponds to <code>logσ2</code>, denoting the log of the variance parameter of the normal distribution.</p><pre><code class="language-julia hljs">py = neg_logden_indep_normal</code></pre><h2 id="Global-Site,-transformations,-and-priors"><a class="docs-heading-anchor" href="#Global-Site,-transformations,-and-priors">Global-Site, transformations, and priors</a><a id="Global-Site,-transformations,-and-priors-1"></a><a class="docs-heading-anchor-permalink" href="#Global-Site,-transformations,-and-priors" title="Permalink"></a></h2><h3 id="Global-and-site-specific-parameters"><a class="docs-heading-anchor" href="#Global-and-site-specific-parameters">Global and site-specific parameters</a><a id="Global-and-site-specific-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Global-and-site-specific-parameters" title="Permalink"></a></h3><p>In this example, we will assign a fixed value to r0 parameter, treat the K2 parameter as unknown but the same across sites, and predict r1 and K1 for each site separately, based on covariates known at the sites.</p><p>Here we provide initial values for them by using <code>ComponentVector</code>.</p><pre><code class="language-julia hljs">FT = Float32
θM0 = θM = CA.ComponentVector{FT}(r1=0.5, K1=0.2) # separately for each individual
θP0 = θP = CA.ComponentVector{FT}(K2=2.0)  # population: same across individuals, 
θFix = CA.ComponentVector{FT}(r0=0.3) # r0, i.e. not estimated</code></pre><h3 id="Parameter-Transformations"><a class="docs-heading-anchor" href="#Parameter-Transformations">Parameter Transformations</a><a id="Parameter-Transformations-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Transformations" title="Permalink"></a></h3><p>HVI allows for transformations of parameters in an unconstrained space, where the probability density is not strictly zero anywhere to the original constrained space.</p><p>Here, our model parameters are strictly positive, and we use the exponential function to transform unconstrained estimates to the original constrained domain.</p><pre><code class="language-julia hljs">transP = Stacked(HVI.Exp())  
transM = Stacked(HVI.Exp(), HVI.Exp())</code></pre><p>Parameter transformations are specified using the <code>Bijectors</code> package. Because, <code>Bijectors.elementwise(exp)</code>, has problems with automatic differentiation (AD) on GPU, we use the public but non-exported <a href="../../reference/reference_public/#HybridVariationalInference.Exp"><code>Exp</code></a> wrapper inside <code>Bijectors.Stacked</code>.</p><h3 id="Prior-information-on-parameters-at-constrained-scale"><a class="docs-heading-anchor" href="#Prior-information-on-parameters-at-constrained-scale">Prior information on parameters at constrained scale</a><a id="Prior-information-on-parameters-at-constrained-scale-1"></a><a class="docs-heading-anchor-permalink" href="#Prior-information-on-parameters-at-constrained-scale" title="Permalink"></a></h3><p>HVI is an approximate bayesian analysis and combines prior information on the parameters with the model and observed data.</p><p>Here, we provide a wide prior by fitting a Lognormal distributions to</p><ul><li>the mode corresponding to the initial value provided above</li><li>the 0.95-quantile 3 times the mode</li></ul><p>using the <code>DistributionFits.jl</code> package.</p><pre><code class="language-julia hljs">θall = vcat(θP, θM)
priors_dict = Dict{Symbol, Distribution}(
    keys(θall) .=&gt; fit.(LogNormal, θall, QuantilePoint.(θall .* 3, 0.95), Val(:mode)))</code></pre><h2 id="Observations,-model-drivers-and-covariates"><a class="docs-heading-anchor" href="#Observations,-model-drivers-and-covariates">Observations, model drivers and covariates</a><a id="Observations,-model-drivers-and-covariates-1"></a><a class="docs-heading-anchor-permalink" href="#Observations,-model-drivers-and-covariates" title="Permalink"></a></h2><p>The model parameters are inverted using information on the</p><ul><li>observed data, <code>y_o</code></li><li>its uncertainty, <code>y_unc</code></li><li>known covariates across sites, <code>xM</code></li><li>model drivers, <code>xP</code></li></ul><p>Here, we use synthetic data generated by the package.</p><pre><code class="language-julia hljs">rng = StableRNG(111)
(; xM, xP, y_o, y_unc) = gen_hybridproblem_synthetic(
    rng, DoubleMM.DoubleMMCase(); scenario=Val((:omit_r0,)))</code></pre><p>Lets look at them.</p><pre><code class="language-julia hljs">size(xM), size(xP), size(y_o), size(y_unc)</code></pre><pre><code class="nohighlight hljs">((5, 800), (16, 800), (8, 800), (8, 800))</code></pre><p>All of them have 800 columns, corresponding to 800 sites. There are 5 site-covaritas, 16 values of model drivers, and 8 observations per site.</p><pre><code class="language-julia hljs">xP[:,1]</code></pre><pre><code class="nohighlight hljs">ComponentVector{Float32}(S1 = Float32[0.5, 0.5, 0.5, 0.5, 0.4, 0.3, 0.2, 0.1], S2 = Float32[1.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0])</code></pre><p>In each column of the model drivers there is a ComponentVector with components S1 and S2 corresponding to the concentrations, for which outputs were observed. This allows notation <code>x.S1</code> in the PBM above.</p><p>The <code>y_unc</code> becomes its meaning by the Likelihood-function to be specified with the problem below.</p><h3 id="Providing-data-in-batches"><a class="docs-heading-anchor" href="#Providing-data-in-batches">Providing data in batches</a><a id="Providing-data-in-batches-1"></a><a class="docs-heading-anchor-permalink" href="#Providing-data-in-batches" title="Permalink"></a></h3><p>HVI uses <code>MLUtils.DataLoader</code> to provide batches of the data during each iteration of the solver. In addition to the data, it provides an index to the sites inside a tuple.</p><pre><code class="language-julia hljs">n_site = size(y_o,2)
n_batch = 20
train_dataloader = MLUtils.DataLoader(
    (CA.getdata(xM), CA.getdata(xP), y_o, y_unc, 1:n_site), 
    batchsize=n_batch, partial=false)</code></pre><h2 id="The-Machine-Learning-model"><a class="docs-heading-anchor" href="#The-Machine-Learning-model">The Machine-Learning model</a><a id="The-Machine-Learning-model-1"></a><a class="docs-heading-anchor-permalink" href="#The-Machine-Learning-model" title="Permalink"></a></h2><p>The machine-learning (ML) part predicts parameters of the posterior of site-specific PBM parameters, given the covariates. Here, we specify a 3-layer feed-forward neural network using the <code>SimpleChains</code> framework which works efficiently on CPU.</p><pre><code class="language-julia hljs">n_out = length(θM) # number of individuals to predict 
n_input = n_covar = size(xM,1)

g_chain = SimpleChain(
    static(n_input), # input dimension (optional)
    TurboDense{true}(tanh, n_input * 4),
    TurboDense{true}(tanh, n_input * 4),
    # dense layer without bias that maps to n outputs to (0..1)
    TurboDense{false}(logistic, n_out)
)
# get a template of the parameter vector, ϕg0
g_chain_app, ϕg0 = construct_ChainsApplicator(rng, g_chain)</code></pre><p>The <code>g_chain_app</code> <code>ChainsApplicator</code> predicts the parameters of the posterior, approximation given a vector of ML weights,<code>ϕg</code>. During construction, an initial template of this vector is created. This abstraction layer allows to use different ML frameworks and replace the <code>SimpleChains</code> model by <code>Flux</code> or <code>Lux</code>.</p><h3 id="Using-priors-to-scale-ML-parameter-estimates"><a class="docs-heading-anchor" href="#Using-priors-to-scale-ML-parameter-estimates">Using priors to scale ML-parameter estimates</a><a id="Using-priors-to-scale-ML-parameter-estimates-1"></a><a class="docs-heading-anchor-permalink" href="#Using-priors-to-scale-ML-parameter-estimates" title="Permalink"></a></h3><p>In order to balance gradients, the <code>g_chain_app</code> ModelApplicator defined above predicts on a scale (0..1). Now the priors are used to translate this to the parameter range by using the cumulative density distribution.</p><p>Priors were specified at constrained scale, but the ML model predicts parameters on unconstrained scale. This transformation of the distribution can be mathematically worked out for specific prior distribution forms. However, for simplicity, a <a href="../../reference/reference_public/#HybridVariationalInference.NormalScalingModelApplicator"><code>NormalScalingModelApplicator</code></a> is fitted to the transformed 5% and 95% quantiles of the original prior.</p><pre><code class="language-julia hljs">priorsM = Tuple(priors_dict[k] for k in keys(θM))
lowers, uppers = get_quantile_transformed(priorsM, transM)
g_chain_scaled = NormalScalingModelApplicator(g_chain_app, lowers, uppers, FT)</code></pre><p>The <code>g_chain_scaled</code> <code>ModelApplicator</code> now predicts in unconstrained scale, transforms logistic predctions around 0.5 to the range of high prior probability of the parameters, and transforms ML predictions near 0 or 1 towards the outer lower probability ranges.</p><h2 id="Assembling-the-information"><a class="docs-heading-anchor" href="#Assembling-the-information">Assembling the information</a><a id="Assembling-the-information-1"></a><a class="docs-heading-anchor-permalink" href="#Assembling-the-information" title="Permalink"></a></h2><p>All the specifications above are stored in a <a href="../../reference/reference_public/#HybridVariationalInference.HybridProblem"><code>HybridProblem</code></a> structure.</p><p>Before, a <a href="../../reference/reference_public/#HybridVariationalInference.PBMSiteApplicator-Tuple{Any}"><code>PBMSiteApplicator</code></a> is constructed that translates an invocation given a vector of global parameters, and a matrix of site parameters to invocation of the process based model (PBM), defined at the beginning.</p><pre><code class="language-julia hljs">f_batch = PBMSiteApplicator(f_doubleMM; θP, θM, θFix, xPvec=xP[:,1])
ϕq0 = init_hybrid_ϕq(MeanHVIApproximation(), θP, θM, transP)

prob = HybridProblem(θM, ϕq0, g_chain_scaled, ϕg0, 
    f_batch, priors_dict, py,
    transM, transP, train_dataloader, n_covar, n_site, n_batch)</code></pre><h2 id="Perform-the-inversion"><a class="docs-heading-anchor" href="#Perform-the-inversion">Perform the inversion</a><a id="Perform-the-inversion-1"></a><a class="docs-heading-anchor-permalink" href="#Perform-the-inversion" title="Permalink"></a></h2><p>Eventually, having assembled all the moving parts of the HVI, we can perform the inversion.</p><pre><code class="language-julia hljs"># silence warning of no GPU backend found (because we did not import CUDA here)
ENV[&quot;MLDATADEVICES_SILENCE_WARN_NO_GPU&quot;] = 1</code></pre><pre><code class="language-julia hljs">using OptimizationOptimisers
import Zygote

solver = HybridPosteriorSolver(; alg=Adam(0.02), n_MC=3)

(; probo, interpreters) = solve(prob, solver; rng,
    callback = callback_loss(100), # output during fitting
    epochs = 2,
);</code></pre><p>The solver object is constructed given the specific stochastic optimization algorithm and the number of Monte-Carlo samples that are drawn in each iteration from the predicted parameter posterior.</p><p>Then the solver is applied to the problem using <a href="../../reference/reference_internal/#CommonSolve.solve-Union{Tuple{omit_priors}, Tuple{is_infer}, Tuple{scen}, Tuple{AbstractHybridProblem, HybridPosteriorSolver}} where {scen, is_infer, omit_priors}"><code>solve</code></a> for a given number of iterations or epochs. For this tutorial, we additionally specify that the function to transfer structures to the GPU is the identity function, so that all stays on the CPU, and this tutorial hence does not require ad GPU or GPU libraries.</p><p>Among the return values are</p><ul><li><code>probo</code>: A copy of the HybridProblem, with updated optimized parameters</li><li><code>interpreters</code>: A <code>NamedTuple</code> with several <code>ComponentArrayInterpreter</code>s that</li></ul><p>will help analyzing the results.</p><h2 id="Using-a-population-level-process-based-model"><a class="docs-heading-anchor" href="#Using-a-population-level-process-based-model">Using a population-level process-based model</a><a id="Using-a-population-level-process-based-model-1"></a><a class="docs-heading-anchor-permalink" href="#Using-a-population-level-process-based-model" title="Permalink"></a></h2><p>So far, the process-based model ran for each single site. For this simple model, some performance grains result from matrix-computations when running the model for all sites within one batch simultaneously.</p><p>In the following, the PBM specification accepts matrices as arguments for parameters and drivers and returns a matrix of precitions. For the parameters, one row corresponds to one site. For the drivers and predictions, one column corresponds to one site.</p><pre><code class="language-julia hljs">function f_doubleMM_sites(θc::CA.ComponentMatrix, xPc::CA.ComponentMatrix)
    # extract several covariates from xP
    S1 = view(xPc, Val(:S1), :)
    S2 = view(xPc, Val(:S2), :)
    #
    # extract the parameters as row-repeated vectors
    #   θc[:,:r0] is parameter r0 for each site in batch
    #   dot-multiplication  of full matrix times row-vector repeats for each observation row
    #   also introduces zero for missing observations, leading to zero gradient there
    is_valid = isfinite.(S1) .&amp;&amp; isfinite.(S2)
    r0 = is_valid .* CA.getdata(θc[:, Val(:r0)])&#39;
    r1 = is_valid .* CA.getdata(θc[:, Val(:r1)])&#39;
    K1 = is_valid .* CA.getdata(θc[:, Val(:K1)])&#39;
    K2 = is_valid .* CA.getdata(θc[:, Val(:K2)])&#39;
    # each variable is a matrix (n_obs x n_site)
    r0 .+ r1 .* S1 ./ (K1 .+ S1) .* S2 ./ (K2 .+ S2)
end</code></pre><p>Again, the function should not rely on the order of parameters but use symbolic indexing to extract the parameter vectors.</p><p>A corresponding <a href="../../reference/reference_public/#HybridVariationalInference.PBMPopulationApplicator-Tuple{Any, Any}"><code>PBMPopulationApplicator</code></a> transforms calls with partitioned global and site parameters to calls of this matrix version of the PBM. The HVI Problem needs to be updated with this new applicatior.</p><pre><code class="language-julia hljs">f_batch = PBMPopulationApplicator(f_doubleMM_sites, n_batch; θP, θM, θFix, xPvec=xP[:,1])
probo_sites = HybridProblem(probo; f_batch)</code></pre><p>For numerical efficiency, the number of sites within one batch is part of the <code>PBMPopulationApplicator</code>. The problem stores an applicator for <code>n_batch</code> sites, however, an applicator for <code>n_site_pred</code> sites can be obtained by <code>create_nsite_applicator(f_batch, n_site_pred)</code>.</p><pre><code class="language-julia hljs">(; probo) = solve(probo_sites, solver; rng,
    callback = callback_loss(100), # output during fitting
    epochs = 20,
    #is_inferred = Val(true), # activate type-checks 
);</code></pre><h2 id="Saving-the-results"><a class="docs-heading-anchor" href="#Saving-the-results">Saving the results</a><a id="Saving-the-results-1"></a><a class="docs-heading-anchor-permalink" href="#Saving-the-results" title="Permalink"></a></h2><p>Extracting useful information from the optimized HybridProblem is covered in the following <a href="../inspect_results/#Inspect-results-of-fitted-problem">Inspect results of fitted problem</a> tutorial. In order to use the results from this tutorial in other tutorials, the updated <code>probo</code> <code>HybridProblem</code> and the interpreters are saved to a JLD2 file.</p><p>Before the problem is updated, so that it uses the redefinition <a href="../../reference/reference_public/#HybridVariationalInference.DoubleMM.f_doubleMM_sites-Tuple{ComponentArrays.ComponentMatrix, ComponentArrays.ComponentMatrix}"><code>DoubleMM.f_doubleMM_sites</code></a> of the PBM in module <code>DoubleMM</code> rather than module <code>Main</code> to allow for easier reloading with JLD2.</p><pre><code class="language-julia hljs">f_batch = PBMPopulationApplicator(DoubleMM.f_doubleMM_sites, n_batch; θP, θM, θFix, xPvec=xP[:,1])
probo2 = HybridProblem(probo; f_batch)</code></pre><pre><code class="language-julia hljs">using JLD2
fname = &quot;intermediate/basic_cpu_results.jld2&quot;
mkpath(&quot;intermediate&quot;)
if probo2 isa AbstractHybridProblem # do not save on failure above
    jldsave(fname, false, IOStream; probo=probo2, interpreters)
end</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../problem/">« Problem</a><a class="docs-footer-nextpage" href="../inspect_results/">Inspect results »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 13 February 2026 15:56">Friday 13 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
