<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>.. specify log-Likelihood · HybridVariationalInference.jl</title><meta name="title" content=".. specify log-Likelihood · HybridVariationalInference.jl"/><meta property="og:title" content=".. specify log-Likelihood · HybridVariationalInference.jl"/><meta property="twitter:title" content=".. specify log-Likelihood · HybridVariationalInference.jl"/><meta name="description" content="Documentation for HybridVariationalInference.jl."/><meta property="og:description" content="Documentation for HybridVariationalInference.jl."/><meta property="twitter:description" content="Documentation for HybridVariationalInference.jl."/><meta property="og:url" content="https://EarthyScience.github.io/HybridVariationalInference.jl/tutorials/logden_user/"/><meta property="twitter:url" content="https://EarthyScience.github.io/HybridVariationalInference.jl/tutorials/logden_user/"/><link rel="canonical" href="https://EarthyScience.github.io/HybridVariationalInference.jl/tutorials/logden_user/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">HybridVariationalInference.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../problem/">Problem</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../basic_cpu/">Basic workflow</a></li><li><a class="tocitem" href="../inspect_results/">Inspect results</a></li></ul></li><li><span class="tocitem">How to</span><ul><li><a class="tocitem" href="../lux_gpu/">.. use GPU</a></li><li class="is-active"><a class="tocitem" href>.. specify log-Likelihood</a><ul class="internal"><li><a class="tocitem" href="#Motivation"><span>Motivation</span></a></li><li><a class="tocitem" href="#Write-the-LogLikelihood-Function"><span>Write the LogLikelihood Function</span></a></li><li><a class="tocitem" href="#Update-the-problem-and-redo-the-inversion"><span>Update the problem and redo the inversion</span></a></li><li><a class="tocitem" href="#Compare-results-between-assumptions-of-observation-error"><span>Compare results between assumptions of observation error</span></a></li></ul></li><li><a class="tocitem" href="../blocks_corr/">.. model independent parameters</a></li><li><a class="tocitem" href="../corr_site_global/">.. model site-global corr</a></li></ul></li><li><span class="tocitem">Explanation</span></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../../reference/reference_public/">Public</a></li><li><a class="tocitem" href="../../reference/reference_internal/">Internal</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How to</a></li><li class="is-active"><a href>.. specify log-Likelihood</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>.. specify log-Likelihood</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/EarthyScience/HybridVariationalInference.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/EarthyScience/HybridVariationalInference.jl/blob/main/docs/src/tutorials/logden_user.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="How-to-specify-a-custom-LogLikelihood-of-the-observations"><a class="docs-heading-anchor" href="#How-to-specify-a-custom-LogLikelihood-of-the-observations">How to specify a custom LogLikelihood of the observations</a><a id="How-to-specify-a-custom-LogLikelihood-of-the-observations-1"></a><a class="docs-heading-anchor-permalink" href="#How-to-specify-a-custom-LogLikelihood-of-the-observations" title="Permalink"></a></h1><p>This guide shows how the user can specify a customized log-Likelihood function.</p><h2 id="Motivation"><a class="docs-heading-anchor" href="#Motivation">Motivation</a><a id="Motivation-1"></a><a class="docs-heading-anchor-permalink" href="#Motivation" title="Permalink"></a></h2><p>The loglikelihood function assigns a cost to the mismatch between predictions and observations. This often needs to be customized to the specific inversion.</p><p>This guide walks through he specification of such a function and inspects differences among two log-likelihood functions. Specifically, it will assume observation errors to be independently distributed according to a LogNormal distribution with a specified fixed relative error, compared to an inversion assuming observation error to be distributed independently normal.</p><p>First load necessary packages.</p><pre><code class="language-julia hljs">using HybridVariationalInference
using ComponentArrays: ComponentArrays as CA
using Bijectors
using SimpleChains
using MLUtils
using JLD2
using Random
using CairoMakie
using PairPlots   # scatterplot matrices</code></pre><p>This tutorial reuses and modifies the fitted object saved at the end of the <a href="../basic_cpu/#Basic-workflow-without-GPU">Basic workflow without GPU</a> tutorial, that used a log-Likelihood function assuming observation error to be distributed independently normal.</p><pre><code class="language-julia hljs">fname = &quot;intermediate/basic_cpu_results.jld2&quot;
print(abspath(fname))
prob = probo_normal = load(fname, &quot;probo&quot;);</code></pre><h2 id="Write-the-LogLikelihood-Function"><a class="docs-heading-anchor" href="#Write-the-LogLikelihood-Function">Write the LogLikelihood Function</a><a id="Write-the-LogLikelihood-Function-1"></a><a class="docs-heading-anchor-permalink" href="#Write-the-LogLikelihood-Function" title="Permalink"></a></h2><p>The function signature corresponds to the one of <a href="../../reference/reference_public/#HybridVariationalInference.neg_logden_indep_normal-Union{Tuple{ET}, Tuple{AbstractArray, AbstractArray, AbstractArray{ET}}} where ET"><code>neg_logden_indep_normal</code></a>. of signature</p><p><code>neg_log_den_user(y_pred, y_obs, y_unc; kwargs...)</code></p><p>It takes inputs of predictions, <code>y_pred</code>, observations, <code>y_obs</code>, and uncertainties parameters, <code>y_unc</code> and returns the logarithm of the likelihhood up to a constant.</p><p>All of the arguments are vectors of the same length specifying predictions and observations for one site. If <code>y_pred</code>, <code>y_obs</code> are given as a matrix of several column-vectors, their summed Likelihood is computed.</p><p>The density of a LogNormal distribution is</p><p class="math-container">\[
\frac{ 1 }{ x  \sqrt{2 \pi \sigma^2} } \exp\left( -\frac{ (\ln x-\mu)^2 }{2 \sigma^2} \right)\]</p><p>where x is the observation, μ is the log of the prediction, and σ is the scale parameter that is related to the relative error, <span>$c_v$</span> by <span>$\sigma = \sqrt{ln(c^2_v + 1)}$</span>.</p><p>Taking the log:</p><p class="math-container">\[
 -ln x -\frac{1}{2} ln \sigma^2 -\frac{1}{2} ln (2 \pi) -\frac{ (\ln x-\mu)^2 }{2 \sigma^2}\]</p><p>Negating and dropping the constants <span>$-\frac{1}{2} ln (2 \pi)$</span> and <span>$-\frac{1}{2} ln \sigma^2$</span></p><p class="math-container">\[
 ln x + \frac{1}{2} \left(\frac{ (\ln x-\mu)^2 }{\sigma^2} \right)\]</p><pre><code class="language-julia hljs">function neg_logden_lognormalep_lognormal(y_pred, y_obs::AbstractArray{ET}, y_unc; 
  σ2 = log(abs2(ET(0.02)) + ET(1))) where ET
    lnx = log.(CA.getdata(y_obs))
    μ = log.(CA.getdata(y_pred))
    nlogL = sum(lnx .+ abs2.(lnx .- μ) ./ (ET(2) .* σ2))  
    #nlogL = sum(lnx + (log(σ2) .+ abs2.(lnx .- μ) ./ σ2) ./ ET(2)) # nonconstant σ2
    return (nlogL)
end</code></pre><p>If information on the different relative error by observation was available, we could pass that information using the DataLoader with <code>y_unc</code>, rather than assuming a constant relative error across observations.</p><h2 id="Update-the-problem-and-redo-the-inversion"><a class="docs-heading-anchor" href="#Update-the-problem-and-redo-the-inversion">Update the problem and redo the inversion</a><a id="Update-the-problem-and-redo-the-inversion-1"></a><a class="docs-heading-anchor-permalink" href="#Update-the-problem-and-redo-the-inversion" title="Permalink"></a></h2><p>HybridProblem has keyword argument <code>py</code> to specify the function of negative Log-Likelihood.</p><pre><code class="language-julia hljs">prob_lognormal = HybridProblem(prob; py = neg_logden_lognormalep_lognormal)

using OptimizationOptimisers
import Zygote

solver = HybridPosteriorSolver(; alg=Adam(0.02), n_MC=3)

(; probo) = solve(prob_lognormal, solver; 
    callback = callback_loss(100), # output during fitting
    epochs = 20,
); probo_lognormal = probo;</code></pre><h2 id="Compare-results-between-assumptions-of-observation-error"><a class="docs-heading-anchor" href="#Compare-results-between-assumptions-of-observation-error">Compare results between assumptions of observation error</a><a id="Compare-results-between-assumptions-of-observation-error-1"></a><a class="docs-heading-anchor-permalink" href="#Compare-results-between-assumptions-of-observation-error" title="Permalink"></a></h2><p>First, draw a sample form the inversion assumping normal and a sample from the inversion assuming loglornally distributed observation errors.</p><pre><code class="language-julia hljs">n_sample_pred = 400
(y_normal, θsP_normal, θsMs_normal) = (; y, θsP, θsMs) = predict_hvi(
  Random.default_rng(), probo_normal; n_sample_pred)
(y_lognormal, θsP_lognormal, θsMs_lognormal) = (; y, θsP, θsMs) = predict_hvi(
  Random.default_rng(), probo_lognormal; n_sample_pred)</code></pre><p>Get the original observations from the DataLoader of the problem, and compute the residuals.</p><pre><code class="language-julia hljs">train_loader = get_hybridproblem_train_dataloader(probo_normal; scenario=())
y_o = train_loader.data[3]
resid_normal = y_o .- y_normal
resid_lognormal = y_o .- y_lognormal</code></pre><p>And compare plots of some of the results.</p><pre><code class="language-julia hljs">i_out = 4
i_site = 1
fig = Figure(); ax = Axis(fig[1,1], xlabel=&quot;observations error (y_obs - y_pred)&quot;,ylabel=&quot;probability density&quot;)
#hist!(ax, resid_normal[i_out,i_site,:], label=&quot;normal&quot;, normalization=:pdf)
density!(ax, resid_normal[i_out,i_site,:], alpha = 0.8, label=&quot;normal&quot;)
density!(ax, resid_lognormal[i_out,i_site,:], alpha = 0.8, label=&quot;lognormal&quot;)
axislegend(ax, unique=true)
fig</code></pre><p><img src="../logden_user_files/figure-commonmark/cell-8-output-1.png" alt/></p><p>The density plot of the observation residuals does not show the lognormal shape. The used synthetic observations were actually noramally distributed around predictions with true parameters.</p><p>How does the wrong assumption of observation error influence the parameter posterior?</p><pre><code class="language-julia hljs">i_site = 1
fig = Figure(); ax = Axis(fig[1,1], xlabel=&quot;global parameter K2&quot;,ylabel=&quot;probability density&quot;)
#hist!(ax, resid_normal[i_out,i_site,:], label=&quot;normal&quot;, normalization=:pdf)
density!(ax, θsP_normal[:K2,:], alpha = 0.8, label=&quot;normal&quot;)
density!(ax, θsP_lognormal[:K2,:], alpha = 0.8, label=&quot;lognormal&quot;)
axislegend(ax, unique=true)
fig</code></pre><p><img src="../logden_user_files/figure-commonmark/cell-9-output-1.png" alt/></p><p>The marginal posterior of the global parameters is also similar, with a small trend towards lower values.</p><pre><code class="language-julia hljs">i_site = 1
θln = vcat(θsP_lognormal, θsMs_lognormal[i_site,:,:])
θln_nt = NamedTuple(Symbol(&quot;$(k)_lognormal&quot;) =&gt; CA.getdata(θln[k,:]) for k in keys(θln[:,1])) # 
#θn = vcat(θsP_normal, θsMs_normal[i_site,:,:])
#θn_nt = NamedTuple(Symbol(&quot;$(k)_normal&quot;) =&gt; CA.getdata(θn[k,:]) for k in keys(θn[:,1])) # 
# ntc = (;θn_nt..., θln_nt...)
plt = pairplot(θln_nt)</code></pre><p><img src="../logden_user_files/figure-commonmark/cell-10-output-1.png" alt/></p><p>The corner plot of the independent-parameters estimate   looks similar and shows correlations between site parameters, <span>$r_1$</span> and <span>$K_1$</span>.</p><pre><code class="language-julia hljs">i_out = 4
fig = Figure(); ax = Axis(fig[1,1], xlabel=&quot;mean(y)&quot;,ylabel=&quot;sd(y)&quot;)
ymean_normal = [mean(y_normal[i_out,s,:]) for s in axes(y_normal, 2)]
ysd_normal = [std(y_normal[i_out,s,:]) for s in axes(y_normal, 2)]
scatter!(ax, ymean_normal, ysd_normal, label=&quot;normal&quot;) 
ymean_lognormal = [mean(y_lognormal[i_out,s,:]) for s in axes(y_lognormal, 2)]
ysd_lognormal = [std(y_lognormal[i_out,s,:]) for s in axes(y_lognormal, 2)]
scatter!(ax, ymean_lognormal, ysd_lognormal, label=&quot;lognormal&quot;) 
axislegend(ax, unique=true)
fig</code></pre><p><img src="../logden_user_files/figure-commonmark/cell-11-output-1.png" alt/></p><p>The predicted magnitude of error in predictions for the fourth observation across sites is of the same magnitude, and still shows (although weaker) pattern of decreasing uncertainty with increasing value.</p><pre><code class="language-julia hljs">plot_sd_vs_mean = (par) -&gt; begin
  fig = Figure(); ax = Axis(fig[1,1], xlabel=&quot;mean($par)&quot;,ylabel=&quot;sd($par)&quot;)
  θmean_normal = [mean(θsMs_normal[s,par,:]) for s in axes(θsMs_normal, 1)]
  θsd_normal = [std(θsMs_normal[s,par,:]) for s in axes(θsMs_normal, 1)]
  scatter!(ax, θmean_normal, θsd_normal, label=&quot;normal&quot;) 
  θmean_lognormal = [mean(θsMs_lognormal[s,par,:]) for s in axes(θsMs_lognormal, 1)]
  θsd_lognormal = [std(θsMs_lognormal[s,par,:]) for s in axes(θsMs_lognormal, 1)]
  scatter!(ax, θmean_lognormal, θsd_lognormal, label=&quot;lognormal&quot;) 
  axislegend(ax, unique=true)
  fig
end
plot_sd_vs_mean(:K1)</code></pre><p><img src="../logden_user_files/figure-commonmark/cell-12-output-1.png" alt/></p><p>For the assumed fixed relative error,the uncertainty in the model parameters, <span>$K_1$</span>, across sites is similar to the uncertainty with normal log-likelihood.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../lux_gpu/">« .. use GPU</a><a class="docs-footer-nextpage" href="../blocks_corr/">.. model independent parameters »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 13 February 2026 15:41">Friday 13 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
