"""
Cost function (ELBO) for hybrid model with batched sites.

It generates n_MC samples for each site, and uses these to compute the
expected value of the likelihood of observations.

## Arguments
- `rng`: random number generator (ignored on CUDA, if ϕ is a AbstractGPUArray)
- `ϕ`: flat vector of parameters
  interpreted by interpreters.μP_ϕg_unc and interpreters.PMs
- `g`: machine learning model
- `transPMs`: Transformations as generated by get_transPMs returned from init_hybrid_params
- `f`: mechanistic model
- `py`: negative log-likelihood of observations given predictions: 
  `function(y_ob, y_pred, y_unc)`
- `xM`, `xP`, `y_ob`, `y_unc`, `i_sites`: information of the sites in the current minibatch
    - `xM`: matrix of covariates (n_cov x n_site_batch)
    - `xP`: model drivers, iterable of (n_site_batch)
    - `y_ob`: matrix of observations (n_obs x n_site_batch)
    - `y_unc`: observation uncertainty provided to py (same size as y_ob)
    - `i_sites`: indices of sites for current minibatch
- `interpreters`: NamedTuple as generated by `gen_hybridproblem_synthetic` with entries:
  - `μP_ϕg_unc`: extract components of parameter of 
    1) means of global PBM, 2) ML-weights, and 3) additional parameters of approximation q
  - `PMs`: assign components to PBM parameters 1 global, 2 matrix of n_site column  vectors
  - `int_unc` (can be omitted, if `μP_ϕg_unc(ϕ).unc` is already a ComponentVector)
- `n_MC`: number of MonteCarlo samples from the distribution of parameters to simulate
  using the mechanistic model f.
"""
function neg_elbo_gtf(args...; kwargs...)
    nLy, entropy_ζ, nLmean_θ = neg_elbo_gtf_components(args...; kwargs...)
    nLy - entropy_ζ + nLmean_θ
end

function neg_elbo_gtf_components(rng, ϕ::AbstractVector, g, f, py,
        xM::AbstractMatrix, xP, y_ob, y_unc, i_sites::AbstractVector{<:Number},
        interpreters::NamedTuple, transform_tools;
        n_MC = 12, n_MC_mean = 30, n_MC_cap = n_MC,
        cdev = cpu_device(),
        priors_θ_mean = [],
        cor_ends, # =(P=(1,),M=(1,))
        pbm_covar_indices
)
    n_MCr = isempty(priors_θ_mean) ? n_MC : max(n_MC, n_MC_mean)
    ζs, σ = generate_ζ(rng, g, ϕ, xM; n_MC = n_MCr, cor_ends, pbm_covar_indices,
        int_unc = interpreters.unc, int_μP_ϕg_unc = interpreters.μP_ϕg_unc, int_PMs = interpreters.PMs
    )
    ζs_cpu = cdev(ζs) # fetch to CPU, because for <1000 sites (n_batch) this is faster
    # translate in batch 

    nLy, entropy_ζ = neg_elbo_ζtf(ζs_cpu, σ, f, py,
        xP, y_ob, y_unc, transform_tools;
        n_MC, n_MC_cap
    )
    nLmean_θ = isempty(priors_θ_mean) ? 0.0 :
    begin
        # compute the mean of predicted and transformed site-parameters
        # avoid mapslices because of Zygote
        # θs0 = mapslices(transPMs, ζs_cpu, dims=[1])
        # θPs0 = mapslices(θ -> interpreters.PMs(θ).P, θs0, dims = 1) 
        #θs = (transPMs(ζ) for ζ in eachcol(ζs_cpu)) # does not work with Zygote
        θs = map(transPMs, eachcol(ζs_cpu))
        θPs = map(θ -> CA.getdata(interpreters.PMs(θ).P), θs) |> stack
        # does not need to allocate vectors but does not work with Zygote: 
        # θPs = (CA.getdata(interpreters.PMs(θ).P) for θ in θs) |> stack
        mean_θP = mean(CA.getdata(θPs); dims = (2))[:, 1]
        #nLmean_θP = map((d, θi) -> -logpdf(d, θi), CA.getdata(priors_θ_mean.P), mean_θP) 
        #workaround for Zygote failing on `priors_θ_mean.P`
        iθ = CA.ComponentArray(1:length(priors_θ_mean), CA.getaxes(priors_θ_mean))
        # need to apply different dist to each entry in θP and mean_θMs -> @allowscalar
        #   but does not work with Zygote
        nLmean_θP = map((d, θi) -> -logpdf(d, θi), priors_θ_mean[CA.getdata(iθ.P)], mean_θP)
        θMss = map(θ -> interpreters.PMs(θ).Ms, θs) |> stack
        mean_θMs = mean(θMss; dims = (3))[:, :, 1]
        nLmean_θMs = map((d, θi) -> -logpdf(d, θi),
            CA.getdata(priors_θ_mean[CA.getdata(iθ.Ms)])[:, i_sites], mean_θMs)
        nLmean_θ = sum(nLmean_θP) + sum(nLmean_θMs)
    end
    nLy, entropy_ζ, nLmean_θ
end

function neg_elbo_ζtf(ζs, σ, f, py,
        xP, y_ob, y_unc,
        transform_tools;
        #interpreters::NamedTuple; 
        n_MC = 12, n_MC_cap = n_MC
)
    nLys = map(eachcol(ζs[:, 1:n_MC])) do ζi
        θP, θMs, logjac = transform_ζ(ζi, transform_tools...)
        y_pred_global, y_pred_i = f(θP, θMs, xP)
        # TODO nLogDen prior on \theta
        #nLy1 = neg_logden_indep_normal(y_ob, y_pred_i, y_unc)
        nLy1 = py(y_ob, y_pred_i, y_unc)
        nLy1 - logjac
    end
    # For robustness may compute the expectation only on the n_smallest values
    # because its very sensitive to few large outliers
    #nLys_smallest = nsmallest(n_MC_cap, nLys) # does not work with Zygote
    if n_MC_cap == n_MC
        nLy = sum(nLys) / n_MC
    else
        nLys_smallest = partialsort(nLys, 1:n_MC_cap)
        nLy = sum(nLys_smallest) / n_MC_cap
    end
    #  sum_log_σ = sum(log.(σ))
    # logdet_jacT2 = -sum_log_σ # log Prod(1/σ_i) = -sum log σ_i 
    logdetΣ = 2 * sum(log.(σ))
    entropy_ζ = entropy_MvNormal(size(ζs, 1), logdetΣ)  # defined in logden_normal
    # if i_sites[1] == 1
    #     #Main.@infiltrate_main
    #     @show nLy, entropy_ζ, nLmean_θ, n_MC, n_MC_cap, i_sites[1:3]
    #     @show std(nLys), std(nLys)/abs(nLy)
    #     @show std(nLys_smallest), std(nLys_smallest)/abs(nLy)
    # end
    nLy, entropy_ζ
end

() -> begin
    nLy = reduce(
        +, map(eachcol(ζs_cpu[:, 1:n_MC])) do ζi
            θ_i, y_pred_i, logjac = predict_y(ζi, xP, f, transPMs, interpreters.PMs)
            # TODO nLogDen prior on \theta
            #nLy1 = neg_logden_indep_normal(y_ob, y_pred_i, y_unc)
            nLy1 = py(y_ob, y_pred_i, y_unc)
            nLy1 - logjac
        end) / n_MC
end

() -> begin
    # using UnicodePlots
    histogram(nLys)
end

"""
    predict_gf(rng, g, f, ϕ::AbstractVector, xM::AbstractMatrix, interpreters;
        get_transPMs, get_ca_int_PMs, n_sample_pred=200, gdev = identity)

Prediction function for hybrid model. Returns an NamedTuple with entries
- `θ`: ComponentArray `(n_θP + n_site * n_θM), n_sample_pred)` of PBM model parameters.
- `y`: Array `(n_obs, n_site, n_sample_pred)` of model predictions.
"""
function predict_gf(rng, prob::AbstractHybridProblem; scenario, kwargs...)
    dl = get_hybridproblem_train_dataloader(prob; scenario)
    dl_dev = gdev_hybridproblem_dataloader(dl; scenario)
    xM, xP = dl_dev.data[1:2]
    predict_gf(rng, prob, xM, xP; scenario, kwargs...)
end
function predict_gf(rng, prob::AbstractHybridProblem, xM::AbstractMatrix, xP;
        scenario,
        n_sample_pred = 200,
        gdev = :use_gpu ∈ scenario ? gpu_device() : identity,
        cdev = gdev isa MLDataDevices.AbstractGPUDevice ? cpu_device() : identity
)
    n_site, n_batch = get_hybridproblem_n_site_and_batch(prob; scenario)
    is_predict_batch = (n_batch == length(xP))
    n_site_pred = is_predict_batch ? n_batch : n_site
    @assert length(xP) == n_site_pred
    @assert size(xM, 2) == n_site_pred
    f = get_hybridproblem_PBmodel(prob; scenario, use_all_sites = !is_predict_batch)
    par_templates = get_hybridproblem_par_templates(prob; scenario)
    (; θP, θM) = par_templates
    cor_ends = get_hybridproblem_cor_ends(prob; scenario)
    g, ϕg0 = get_hybridproblem_MLapplicator(prob; scenario)
    ϕunc0 = get_hybridproblem_ϕunc(prob; scenario)
    (; transP, transM) = get_hybridproblem_transforms(prob; scenario)
    pbm_covars = get_hybridproblem_pbmpar_covars(prob; scenario)
    pbm_covar_indices = get_pbm_covar_indices(θP, pbm_covars)
    (; ϕ, transPMs_batch, interpreters, get_transPMs, get_ca_int_PMs) = init_hybrid_params(
        θP, θM, cor_ends, ϕg0, n_site_pred; transP, transM, ϕunc0)
    g_dev, ϕ_dev = gdev(g), gdev(ϕ)
    predict_gf(rng, g_dev, f, ϕ_dev, xM, xP, interpreters;
        get_transPMs, get_ca_int_PMs, n_sample_pred, cdev, cor_ends, pbm_covar_indices)
end

function predict_gf(rng, g, f, ϕ::AbstractVector, xM::AbstractMatrix, xP, interpreters,
        int_P::AbstractComponentArrayInterpreter,
        int_M::AbstractComponentArrayInterpreter;
        #get_transPMs, 
        transP, transM,
        get_ca_int_PMs, n_sample_pred = 200,
        cdev = cpu_device(),
        cor_ends,        #cor_ends=(P=(1,),M=(1,))
        pbm_covar_indices,
        int_PMs = get_concrete(construct_int_PMs_parfirst(int_P, int_M, size(xP, 2))),
        intm_PMs = get_concrete(ComponentArrayInterpreter(int_PMs, (n_sample_pred,))),
        int_unc,
        kwargs...
)
    n_site = size(xM, 2)
    #trans_PMs_gen = get_transPMs(n_site)
    ζs_gpu, σ = generate_ζ(rng, g, CA.getdata(ϕ), CA.getdata(xM);
        int_PMs, int_μP_ϕg_unc = interpreters.μP_ϕg_unc,
        n_MC = n_sample_pred, cor_ends, pbm_covar_indices, int_unc)
    ζs = cdev(ζs_gpu)
    logdetΣ = 2 * sum(log.(σ))
    entropy_ζ = entropy_MvNormal(length(σ), logdetΣ)  # defined in logden_normal
    #(; θs, y, intm_PMst) = predict_ζf(ζs, f, xP, transP, transM, interpreters_gen.PMs, int_P, int_Ms)
    #(; θs, y, intm_PMst) = predict_ζf(ζs, f, xP, transP, transM, int_P, int_M; int_PMs = intm_PMs_gen)
    #(; θs, y, intm_PMst) = 
    return predict_ζf(ζs, f, xP, transP, transM, int_P, int_M; int_PMs, kwargs...)
    #(; θs, y, entropy_ζ, intm_PMst)
end

function predict_ζf(ζs, f, xP, transP, transM::Stacked,
        int_P::AbstractComponentArrayInterpreter, int_M;
        int_PMs = get_concrete(construct_int_PMs_parfirst(int_P, int_M, size(xP, 2))),
        int_PMst = get_concrete(construct_int_PMs_sitefirst(int_P, int_M, size(xP, 2))),
        intm_PMst = get_concrete(ComponentArrayInterpreter(int_PMst, (size(ζs, 2),)))
)
    # MAYBE transform entirey ζs at once for performance, since no logdetjac needed here
    n_site_batch = size(xP, 2)
    int_Ms = ComponentArrayInterpreter((n_site_batch,), int_M)
    θP_θMs_y = map(eachcol(ζs)) do ζ
        θP_θMs_y_i = predict_y(ζ, xP, f, transP, transM, int_PMs, int_P, int_Ms)[1:3]
    end
    # θP_θMs_y_1 = first(θP_θMs_y)
    # int1 = ComponentArrayInterpreter(CA.ComponentVector(P = θP_θMs_y_1[1], Ms = θP_θMs_y_1[2]))
    # #int_PMst = ComponentArrayInterpreter((length(θP_θMs_y),), int1)
    # int_PMst = ComponentArrayInterpreter(int1, (length(θP_θMs_y),))
    #θP_θMs_y_i = θP_θMs_y_1
    θsv = stack(map(θP_θMs_y) do θP_θMs_y_i
        vcat(CA.getdata(θP_θMs_y_i[1]), vec(CA.getdata(θP_θMs_y_i[2])))
    end)
    θs = intm_PMst(θsv)
    #θs[:P,1]
    #θs[:Ms,1]
    y = stack(x -> x[3], θP_θMs_y)
    (; θs, y, intm_PMst)
end

function construct_int_PMs_parfirst(int_P, int_M, n_site)
    int_Ms = ComponentArrayInterpreter(int_M, (n_site,))
    intm_Ms = ComponentArrayInterpreter(P = int_P, Ms = int_Ms)
    #XXTODO
end
function construct_int_PMs_sitefirst(int_P, int_M, n_site)
    int_Ms = ComponentArrayInterpreter((n_site,), int_M)
    ComponentArrayInterpreter(P = int_P, Ms = int_Ms)
end

"""
Generate samples of (inv-transformed) model parameters, ζ, 
and the vector of standard deviations, σ, i.e. the diagonal of the cholesky-factor.

Adds the MV-normally distributed residuals, retrieved by `sample_ζresid_norm`
to the means extracted from parameters and predicted by the machine learning
model. 
"""
function generate_ζ(rng, g, ϕ::AbstractVector, xM::AbstractMatrix;
        int_μP_ϕg_unc::AbstractComponentArrayInterpreter,
        int_PMs::AbstractComponentArrayInterpreter,
        int_unc::AbstractComponentArrayInterpreter,
        n_MC = 3, cor_ends, pbm_covar_indices)
    # see documentation of neg_elbo_gtf
    ϕc = int_μP_ϕg_unc(CA.getdata(ϕ))
    μ_ζP = ϕc.μP
    ϕg = ϕc.ϕg
    # first pass: append μ_ζP_to covars, need ML prediction for magnitude of ζMs
    # TODO replace pbm_covar_indices by ComponentArray? dimensions to be type-inferred?
    xMP = _append_each_covars(xM, CA.getdata(μ_ζP), pbm_covar_indices)
    μ_ζMs0 = g(xMP, ϕg)
    ζ_resid, σ = sample_ζresid_norm(rng, μ_ζP, μ_ζMs0, ϕc.unc; n_MC, cor_ends, int_unc)
    #ζ_resid, σ = sample_ζresid_norm(rng, ϕ[1:2], reshape(ϕ[2 .+ (1:20)],2,:), ϕ[(end-length(interpreters.unc)+1):end], interpreters.unc; n_MC)
    # @show size(ζ_resid)
    # @show length(interpreters.PMs)
    ζ = stack(map(eachcol(ζ_resid)) do r
        rc = int_PMs(r)
        ζP = μ_ζP .+ rc.P
        # second pass: append ζP rather than μ_ζP to covarss to xM
        μ_ζMs = _predict_μ_ζMs(xM, ζP, pbm_covar_indices, g, ϕg, μ_ζMs0)
        ζMs = μ_ζMs .+ rc.Ms
        vcat(ζP, vec(ζMs))
    end)
    ζ, σ
end

# function _append_PBM_covars(xM, ζP, pbm_covars::NTuple{N,Symbol}) where N
#     #@show ζP, typeof(ζP)
#     vcat(xM, hcat(fill(
#         convert(Array{eltype(xM)}, CA.getdata(ζP[pbm_covars])),
#         #similar(CA.getdata(ζP[pbm_covars]), eltype(xM)), # 
#         size(xM,2))...))
# end
# function _append_PBM_covars(xM, ζP, pbm_covars::NTuple{0}) 
#     xM
# end

function _append_each_covars(xM, ζP::AbstractVector, pbm_covar_indices::SA.StaticVector{0})
    xM
end
function _append_each_covars(xM, ζP::AbstractVector, pbm_covar_indices::AbstractVector)
    ζP_covar = ζP[pbm_covar_indices]
    _append_each_covars(xM, ζP_covar)
end
function _append_each_covars(xM, ζP_covar::AbstractVector)
    #@show ζP, typeof(ζP)
    @assert eltype(xM) == eltype(ζP_covar)
    #Main.@infiltrate_main
    ζP_rep = reduce(hcat, fill(ζP_covar, size(xM, 2)))
    vcat(xM, ζP_rep)
end

function get_pbm_covar_indices(ζP, pbm_covars::NTuple{N, Symbol},
        intP::AbstractComponentArrayInterpreter = ComponentArrayInterpreter(ζP)) where {N}
    #SA.SVector{N}(CA.getdata(intP(1:length(intP))[pbm_covars])) # can not index into GPUarr
    CA.getdata(intP(1:length(intP))[pbm_covars])
end
function get_pbm_covar_indices(ζP, pbm_covars::NTuple{0},
        intP::AbstractComponentArrayInterpreter = ComponentArrayInterpreter(ζP))
    SA.SA[]
end

# function _predict_μ_ζMs(xM, ζP, pbm_covars::NTuple{N,Symbol}, g, ϕg, μ_ζMs0) where N
#     xMP2 = _append_PBM_covars(xM, ζP, pbm_covars) # need different variable name?
#     μ_ζMs = g(xMP2, ϕg)
# end
# function _predict_μ_ζMs(xM, ζP, pbm_covars::NTuple{0}, g, ϕg, μ_ζMs0)
#     # if pbm_covars is the empty tuple, just return the original prediction on xM only
#     # rather than calling the ML model
#     μ_ζMs0
# end

function _predict_μ_ζMs(xM, ζP, pbm_covar_indices::AbstractVector, g, ϕg, μ_ζMs0)
    xMP2 = _append_each_covars(xM, CA.getdata(ζP), pbm_covar_indices)
    μ_ζMs = g(xMP2, ϕg)
end
function _predict_μ_ζMs(xM, ζP, pbm_covars_indices::SA.StaticVector{0}, g, ϕg, μ_ζMs0)
    # if pbm_covars is the empty tuple, just return the original prediction on xM only
    # rather than calling the ML model
    μ_ζMs0
end

"""
Extract relevant parameters from θ and return n_MC generated draws
together with the vector of standard deviations, σ.

## Arguments
* `int_unc`: Interpret vector as ComponentVector with components
   ρsP, ρsM, logσ2_logP, coef_logσ2_ζMs(intercept + slope), 
"""
function sample_ζresid_norm(rng::Random.AbstractRNG, ζP::AbstractVector, ζMs::AbstractMatrix,
        args...; n_MC, cor_ends, int_unc, intm_PMs_parfirst=nothing)
    n_θP, n_θMs = length(ζP), length(ζMs)
    intm_PMs_parfirst = !isnothing(intm_PMs_parfirst) ? intm_PMs_parfirst : begin
        n_θM, n_site_batch = size(ζMs)
        get_concrete(ComponentArrayInterpreter(
            P = (n_MC, n_θP), Ms = (n_MC, n_θM, n_site_batch)))
    end
    urandn = _create_randn(rng, CA.getdata(ζP), n_MC, n_θP + n_θMs )
    sample_ζresid_norm(urandn, CA.getdata(ζP), CA.getdata(ζMs), args...;
        cor_ends, int_unc = get_concrete(int_unc), intm_PMs_parfirst)
end

function sample_ζresid_norm(urandn::AbstractMatrix, ζP::TP, ζMs::TM,
        ϕunc::AbstractVector; 
        int_unc = get_concrete(ComponentArrayInterpreter(ϕunc)),
        intm_PMs_parfirst, cor_ends
) where {T, TP <: AbstractVector{T}, TM <: AbstractMatrix{T}}
    ϕuncc = int_unc(CA.getdata(ϕunc))
    n_θP, n_θMs, (n_θM, n_batch) = length(ζP), length(ζMs), size(ζMs)
    # do not create a UpperTriangular Matrix of an AbstractGÜUArray in transformU_cholesky1
    ρsP = isempty(ϕuncc.ρsP) ? similar(ϕuncc.ρsP) : ϕuncc.ρsP # required by zygote
    UP = transformU_block_cholesky1(ρsP, cor_ends.P)
    ρsM = isempty(ϕuncc.ρsM) ? similar(ϕuncc.ρsM) : ϕuncc.ρsM # required by zygote
    UM = transformU_block_cholesky1(ρsM, cor_ends.M)
    cf = ϕuncc.coef_logσ2_ζMs
    logσ2_logMs = vec(cf[1, :] .+ cf[2, :] .* ζMs)
    logσ2_logP = vec(CA.getdata(ϕuncc.logσ2_logP))
    # CUDA cannot multiply BlockDiagonal * Diagonal, construct already those blocks
    σMs = reshape(exp.(logσ2_logMs ./ 2), n_θM, :)
    σP = exp.(logσ2_logP ./ 2)
    # BlockDiagonal does work with CUDA, but not with combination of Zygote and CUDA
    # need to construct full matrix for CUDA
    Uσ = _create_blockdiag(UP, UM, σP, σMs, n_batch)
    #ζ_resid_parfirst = Uσ' * urandn
    ζ_resid_parfirst = urandn * Uσ # n_MC x n_par
    #map(std, eachcol(ζ_resid_parfirst[:, 3:8]))
    ζ_resid = transpose_mPMs_sitefirst(ζ_resid_parfirst; intm_PMs_parfirst)
    #map(std, eachcol(ζ_resid[:, 3:8])) # all ~ 0.1 in sample_ζresid_norm cpu
    #map(std, eachcol(ζ_resid[:, 2 + n_batch .+ (-1:5)])) # all ~ 100, exept first two
    σ = diag(Uσ)   # elements of the diagonal: standard deviations
    # returns AbstractGPUuArrays to either continue on GPU or need to transfer to CPU
    ζ_resid, σ
end

"""
Transforms each row of a matrix (n_MC x n_Par) with site parameters Ms inside n_Par 
of form (n_par x n_site) to Ms of the form (n_site x n_par), i.e. 
neighboring entries (inside a column) are of the same parameter.

This format of having n_par as the last dimension helps transforming parameters
on block.
"""
function transpose_mPMs_sitefirst(Xt, n_θP::Integer, n_θM, n_site_batch, n_MC)
    # cannot make n_θP keyword arguments, because it overrides method below
    intm_PMs_parfirst = ComponentArrayInterpreter(
        P = (n_MC, n_θP), Ms = (n_MC, n_θM, n_site_batch))
    transpose_mPMs_sitefirst(Xt; intm_PMs_parfirst)
end
function transpose_mPMs_sitefirst(Xt;
        intm_PMs_parfirst = ComponentArrayInterpreter(
            P = (n_MC, n_θP), Ms = (n_MC, n_θM, n_site_batch))
            )
    Xtc = intm_PMs_parfirst(Xt)
    # Main.@infiltrate_main

    # _Ms = Xtc.Ms
    # map(std, eachrow(_Ms[:,1:6,:]))

    # map(std, eachrow(tmp[3:8,:]))
    # _Ms = permutedims(Xtc.Ms, (1, 3, 2))
    X_site_first = CA.ComponentVector(P = Xtc.P, Ms = permutedims(Xtc.Ms, (1, 3, 2)))
    reshape(CA.getdata(X_site_first), size(Xt))::typeof(CA.getdata(Xt))
    # X_site_first = CA.ComponentVector(
    #     P = permutedims(Xtc.P), Ms = permutedims(Xtc.Ms, (3, 2, 1)))
    # reshape(CA.getdata(X_site_first), rev(size(Xt)))::typeof(CA.getdata(Xt))
end

function _create_blockdiag(UP::AbstractMatrix{T}, UM, σP, σMs, n_batch) where {T}
    v = [i == 0 ? UP * Diagonal(σP) : UM * Diagonal(σMs[:, i]) for i in 0:n_batch]
    BlockDiagonal(v)
end
function _create_blockdiag(
        UP::GPUArraysCore.AbstractGPUMatrix{T}, UM, σP, σMs, n_batch) where {T}
    # using BlockDiagonal leads to Scalar operations downstream
    # v = [i == 0 ? UP * Diagonal(σP) : UM * Diagonal(σMs[:, i]) for i in 0:n_batch]
    # BlockDiagonal(v)    
    # Uσ = cat([i == 0 ? UP * Diagonal(σP) : UM * Diagonal(σMs[:, i]) for i in 0:n_batch]...;
    #     dims=(1, 2))
    # on GPU use only one big multiplication rather than many small ones
    U = cat([i == 0 ? UP : UM for i in 0:n_batch]...; dims = (1, 2))
    #Main.@infiltrate_main
    σD = Diagonal(vcat(σP, vec(σMs)))
    Uσ = U * σD
    # need for Zygote why?
    # tmp = cat(Uσ; dims=(1,2))
    tmp = vcat(Uσ)
end

function _create_randn(rng, ::AbstractVector{T}, dims...) where {T}
    randn(rng, T, dims...)
end

#moved to HybridVariationalInferenceCUDAExt
#function _create_randn(rng, ::CUDA.CuVector{T}, dims...) where {T}

""" 
Compute predictions and log-Determinant of the transformation at given
transformed parameters for each site. 

The number of sites is given by the number of columns in `Ms`, which is determined
by the transformation, `transPMs`.

Steps:
- transform the parameters to original constrained space
- Applies the mechanistic model for each site
"""
function predict_y(ζi, xP, f, transP, transM::Stacked,
        int_PMs::AbstractComponentArrayInterpreter,
        int_P::AbstractComponentArrayInterpreter,
        int_Ms::AbstractComponentArrayInterpreter)
    θP, θMs, logjac = transform_ζ(ζi, transP, transM, int_PMs)
    #θc, logjac = int_PMs(ζi), eltype(ζi)(0)
    y_pred_global, y_pred = f(θP, θMs, xP)
    # Main.@infiltrate_main
    # @benchmark f(θc.P, θc.Ms, xP)
    #y_pred_global, y_pred = f(θc.P, θc.Ms, xPg)
    # TODO take care of y_pred_global
    # TODO interpret θP and θMs 
    int_P(θP), int_Ms(θMs), y_pred, logjac
end

function transform_ζ(ζi, transPMs::Bijectors.Transform,
        int_PMs::AbstractComponentArrayInterpreter)
    @warn("replace by transform_ζ with pos_int_P, pos_int_Mst")
    # θtup, logjac = transform_and_logjac(transPMs, ζi) # both allocating
    # θc = CA.ComponentVector(θtup)
    #replace with more flexible transPMs after trying CUDA/Zygote            
    #θ, logjac = exp.(ζi), sum(ζi)
    θ, logjac = Bijectors.with_logabsdet_jacobian(transPMs, ζi) # both allocating
    θc = int_PMs(θ)
    θc, logjac
end

function transform_ζ(ζ::AbstractArray,
        transP, transM::Stacked, int_PMs::AbstractComponentArrayInterpreter)
    transP, transMM, pos_int_P, pos_int_Mst = setup_transform_ζ(transP, transM, int_PMs)
    transform_ζ(ζ, transP, transMM, pos_int_P, pos_int_Mst)
end

function setup_transform_ζ(
        transP, transM::Stacked, int_PMs::AbstractComponentArrayInterpreter)
    pos_PMs = get_positions(int_PMs)
    pos_int_Mst = CA.getdata(pos_PMs.Ms)'
    pos_int_P = CA.getdata(pos_PMs.P)
    n_batch = size(pos_int_Mst, 1)
    transMM = extend_stacked_nrow(transM, n_batch)
    (transP, transMM, pos_int_P, pos_int_Mst)
end

function transform_ζ(ζ::AbstractArray, transP, transMM::Stacked,
        pos_int_P::AbstractVector{<:Integer},
        pos_int_Mst::AbstractMatrix{<:Integer}
)
    θP, logjac_P = Bijectors.with_logabsdet_jacobian(transP, ζ[pos_int_P])
    θMsvec, logjac_M = Bijectors.with_logabsdet_jacobian(transMM, vec(ζ[pos_int_Mst]))
    θMs = reshape(θMsvec, size(pos_int_Mst))
    θP, θMs, logjac_P + logjac_M
end
