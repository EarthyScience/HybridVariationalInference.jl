"""
Cost function (ELBO) for hybrid model with batched sites.

It generates n_MC samples for each site, and uses these to compute the
expected value of the likelihood of observations.

## Arguments
- `rng`: random number generator (ignored on CUDA, if ϕ is a AbstractGPUArray)
- `ϕ`: flat vector of parameters
  interpreted by interpreters.μP_ϕg_unc and interpreters.PMs
- `g`: machine learning model
- `transPMs`: Transformations as generated by get_transPMs returned from init_hybrid_params
- `f`: mechanistic model
- `py`: negative log-likelihood of observations given predictions: 
  `function(y_ob, y_pred, y_unc)`
- `xM`, `xP`, `y_ob`, `y_unc`, `i_sites`: information of the sites in the current minibatch
    - `xM`: matrix of covariates (n_cov x n_site_batch)
    - `xP`: model drivers, iterable of (n_site_batch)
    - `y_ob`: matrix of observations (n_obs x n_site_batch)
    - `y_unc`: observation uncertainty provided to py (same size as y_ob)
    - `i_sites`: indices of sites for current minibatch
- `interpreters`: NamedTuple as generated by `gen_hybridproblem_synthetic` with entries:
  - `μP_ϕg_unc`: extract components of parameter of 
    1) means of global PBM, 2) ML-weights, and 3) additional parameters of approximation q
  - `PMs`: assign components to PBM parameters 1 global, 2 matrix of n_site column  vectors
  - `int_unc` (can be omitted, if `μP_ϕg_unc(ϕ).unc` is already a ComponentVector)
- `n_MC`: number of MonteCarlo samples from the distribution of parameters to simulate
  using the mechanistic model f.
"""
function neg_elbo_gtf(args...; kwargs...)
    nLy, entropy_ζ, nLmean_θ = neg_elbo_gtf_components(args...; kwargs...)
    nLy - entropy_ζ + nLmean_θ
end

function neg_elbo_gtf_components(rng, ϕ::AbstractVector{FT}, g, f, py,
    xM::AbstractMatrix, xP, y_ob, y_unc, i_sites::AbstractVector{<:Number};
    int_μP_ϕg_unc::AbstractComponentArrayInterpreter,
    int_unc::AbstractComponentArrayInterpreter,
    n_MC=12, n_MC_mean=n_MC, n_MC_cap=n_MC,
    cdev=cpu_device(),
    priors_θP_mean=[], 
    priors_θMs_mean=[],
    #priors_θ_mean=[],
    cor_ends, # =(P=(1,),M=(1,))
    pbm_covar_indices,
    transP, transMs, 
    trans_mP =StackedArray(transP, n_MC), # provide with creating cost function
    trans_mMs =StackedArray(transMs.stacked, n_MC),
) where {FT}
    n_MCr = isempty(priors_θP_mean) ? n_MC : max(n_MC, n_MC_mean)
    ζsP, ζsMs, σ = generate_ζ(rng, g, ϕ, xM; n_MC=n_MCr, cor_ends, pbm_covar_indices,
        int_unc, int_μP_ϕg_unc)
    ζsP_cpu = cdev(ζsP) # fetch to CPU, because for <1000 sites (n_batch) this is faster
    ζsMs_cpu = cdev(ζsMs) # fetch to CPU, because for <1000 sites (n_batch) this is faster
    #
    # maybe: translate ζ once and supply to both neg_elbo and negloglik_meanθ
    nLy, entropy_ζ = neg_elbo_ζtf(
        ζsP_cpu[:,1:n_MC], ζsMs_cpu[:,:,1:n_MC], σ, f, py, xP, y_ob, y_unc;
        n_MC_cap, transP, transMs, )
    #
    # maybe: provide trans_mP and trans_mMs with creating cost function
    nLmean_θ = _compute_negloglik_meanθ(ζsP_cpu, ζsMs_cpu; 
        trans_mP, trans_mMs, priors_θP_mean, priors_θMs_mean, i_sites)
    nLy, entropy_ζ, nLmean_θ
end

function _compute_negloglik_meanθ(ζsP::AbstractMatrix{FT}, ζsMs; 
    priors_θP_mean, priors_θMs_mean, i_sites, trans_mP, trans_mMs, 
) where FT
    if isempty(priors_θP_mean) 
        return zero(FT)
    end
    θsP, θsMs = transform_ζs(ζsP, ζsMs; trans_mP, trans_mMs)
    mean_θP = mean(CA.getdata(θsP); dims=(2))[:, 1]
    nLmean_θP = map((d, θi) -> -logpdf(d, θi), priors_θP_mean, mean_θP)
    mean_θMs = mean(θsMs; dims=(3))[:, :, 1]
    nLmean_θMs = map((d, θi) -> -logpdf(d, θi), priors_θMs_mean[i_sites], mean_θMs)
    nLmean_θ = sum(nLmean_θP) + sum(nLmean_θMs)
    convert(FT,nLmean_θ)::FT
end

""" 
Compute the neg_elbo for each sampled parameter vector (last dimension of ζs).
- Transform and compute log-jac
- call forward model
- compute log-density of predictions
- compute entropy of transformation
"""
function neg_elbo_ζtf(ζsP, ζsMs, σ, f, py, xP, y_ob, y_unc;
    n_MC_cap=size(ζsP,2),
    transP,
    transMs=StackedArray(transM, size(ζsMs, 2))
)
    n_MC = size(ζsP,2)
    nLys = map(eachcol(ζsP), eachslice(ζsMs; dims=3)) do ζP, ζMs
        θP, θMs, logjac = transform_and_logjac_ζ(ζP, ζMs; transP, transMs)
        y_pred_global, y_pred_i = f(θP, θMs, xP)
        # TODO nLogDen prior on \theta
        #nLy1 = neg_logden_indep_normal(y_ob, y_pred_i, y_unc)
        nLy1 = py(y_ob, y_pred_i, y_unc)
        nLy1 - logjac
    end
    # For robustness may compute the expectation only on the n_smallest values
    # because its very sensitive to few large outliers
    #nLys_smallest = nsmallest(n_MC_cap, nLys) # does not work with Zygote
    if n_MC_cap == n_MC
        nLy = sum(nLys) / n_MC
    else
        nLys_smallest = partialsort(nLys, 1:n_MC_cap)
        nLy = sum(nLys_smallest) / n_MC_cap
    end
    #  sum_log_σ = sum(log.(σ))
    # logdet_jacT2 = -sum_log_σ # log Prod(1/σ_i) = -sum log σ_i 
    logdetΣ = 2 * sum(log.(σ))
    n_θ = size(ζsP, 1) + prod(size(ζsMs)[1:2])
    @assert length(σ) == n_θ
    entropy_ζ = entropy_MvNormal(n_θ, logdetΣ)  # defined in logden_normal
    # if i_sites[1] == 1
    #     #Main.@infiltrate_main
    #     @show nLy, entropy_ζ, nLmean_θ, n_MC, n_MC_cap, i_sites[1:3]
    #     @show std(nLys), std(nLys)/abs(nLy)
    #     @show std(nLys_smallest), std(nLys_smallest)/abs(nLy)
    # end
    nLy, entropy_ζ
end

() -> begin
    nLy = reduce(
        +, map(eachcol(ζs_cpu[:, 1:n_MC])) do ζi
            θ_i, y_pred_i, logjac = apply_f_trans(ζi, xP, f, transPMs, interpreters.PMs)
            # TODO nLogDen prior on \theta
            #nLy1 = neg_logden_indep_normal(y_ob, y_pred_i, y_unc)
            nLy1 = py(y_ob, y_pred_i, y_unc)
            nLy1 - logjac
        end) / n_MC
end

() -> begin
    # using UnicodePlots
    histogram(nLys)
end

"""
    predict_gf(rng, g, f, ϕ::AbstractVector, xM::AbstractMatrix, interpreters;
        get_transPMs, get_ca_int_PMs, n_sample_pred=200, gdev = identity)

Prediction function for hybrid model. Returns an NamedTuple with entries
- `θ`: ComponentArray `(n_θP + n_site * n_θM), n_sample_pred)` of PBM model parameters.
- `y`: Array `(n_obs, n_site, n_sample_pred)` of model predictions.
"""
function predict_gf(rng, prob::AbstractHybridProblem; scenario, kwargs...)
    dl = get_hybridproblem_train_dataloader(prob; scenario)
    dl_dev = gdev_hybridproblem_dataloader(dl; scenario)
    # predict for all sites
    xM, xP = dl_dev.data[1:2]
    predict_gf(rng, prob, xM, xP; scenario, kwargs...)
end
function predict_gf(rng, prob::AbstractHybridProblem, xM::AbstractMatrix, xP;
    scenario,
    n_sample_pred=200,
    gdev=:use_gpu ∈ _val_value(scenario) ? gpu_device() : identity,
    cdev=!(gdev isa MLDataDevices.AbstractGPUDevice) ? identity :
        (:f_on_gpu ∈ _val_value(scenario) ? identity : cpu_device()), 
    kwargs...
)
    n_site, n_batch = get_hybridproblem_n_site_and_batch(prob; scenario)
    is_predict_batch = (n_batch == length(xP))
    n_site_pred = is_predict_batch ? n_batch : n_site
    @assert size(xP, 2) == n_site_pred
    @assert size(xM, 2) == n_site_pred
    f = get_hybridproblem_PBmodel(prob; scenario, use_all_sites=!is_predict_batch)
    par_templates = get_hybridproblem_par_templates(prob; scenario)
    (; θP, θM) = par_templates
    cor_ends = get_hybridproblem_cor_ends(prob; scenario)
    g, ϕg0 = get_hybridproblem_MLapplicator(prob; scenario)
    ϕunc0 = get_hybridproblem_ϕunc(prob; scenario)
    (; transP, transM) = get_hybridproblem_transforms(prob; scenario)
    pbm_covars = get_hybridproblem_pbmpar_covars(prob; scenario)
    pbm_covar_indices = get_pbm_covar_indices(θP, pbm_covars)
    hpints = HybridProblemInterpreters(prob; scenario)
    (; ϕ, transPMs_batch, interpreters, get_transPMs) = init_hybrid_params(
        θP, θM, cor_ends, ϕg0, hpints; transP, transM, ϕunc0)
    int_μP_ϕg_unc = interpreters.μP_ϕg_unc
    int_unc = interpreters.unc
    transMs = StackedArray(transM, n_batch)        
    g_dev, ϕ_dev = gdev(g), gdev(ϕ)
    predict_gf(rng, g_dev, f, ϕ_dev, xM, xP;
        int_μP_ϕg_unc, int_unc, transP, transM, 
        n_sample_pred, cdev, cor_ends, pbm_covar_indices, kwargs...)
end

function predict_gf(rng, g, f, ϕ::AbstractVector, xM::AbstractMatrix, xP;
    int_μP_ϕg_unc::AbstractComponentArrayInterpreter,
    int_unc::AbstractComponentArrayInterpreter,
    transP, transM,
    n_sample_pred=200,
    cdev=cpu_device(),
    cor_ends,
    pbm_covar_indices,
    is_inferred::Val{is_infer} = Val(false),
    kwargs...
) where is_infer
    ζsP, ζsMs, σ = generate_ζ(rng, g, CA.getdata(ϕ), CA.getdata(xM);
        int_μP_ϕg_unc, int_unc,
        n_MC=n_sample_pred, cor_ends, pbm_covar_indices)
    ζsP_cpu = cdev(ζsP)
    ζsMs_cpu = cdev(ζsMs)
    logdetΣ = 2 * sum(log.(σ))
    entropy_ζ = entropy_MvNormal(length(σ), logdetΣ)
    res_pred = is_infer ? 
        apply_f_trans(ζsP_cpu, ζsMs_cpu, f, xP; transP, transM, kwargs...) :
        Test.@inferred apply_f_trans(ζsP_cpu, ζsMs_cpu, f, xP; transP, transM, kwargs...) 
    (; res_pred..., entropy_ζ)
end


""" 
Compute predictions of the transformation at given
transformed parameters for each site. 
The number of sites is given by the number of rows in `ζsMs`.

Steps:
- transform the parameters to original constrained space
- Applies the mechanistic model for each site

`ζsP` and `ζsMs` are shaped according to the output of `generate_ζ`.
Results are of shape `(n_obs x n_site_pred x n_MC)`.
"""
function apply_f_trans(ζsP::AbstractMatrix, ζsMs::AbstractArray, f, xP; transP, transM::Stacked,
    trans_mP=StackedArray(transP, size(ζsP, 2)),
    trans_mMs=StackedArray(transM, size(ζsMs, 1) * size(ζsMs, 3))
)
    θsP, θsMs = transform_ζs(ζsP, ζsMs; trans_mP, trans_mMs)
    y = apply_f(θsP, θsMs, f, xP)
    (; y, θsP, θsMs)
end

function apply_f_trans(ζP::AbstractVector, ζMs::AbstractMatrix, f, xP; 
    transP, transM::Stacked, transMs::StackedArray=StackedArray(transM, size(ζMs, 1)),
)
    θP = transP(ζP)
    θMs = transMs(ζMs)
    y_global, y = f(θP, θMs, xP)
    (; y, θP, θMs)
end


function apply_f(θsP::AbstractMatrix, θsMs::AbstractArray{ET,3}, f, xP) where ET
    y_pred = stack(map(eachcol(θsP), eachslice(θsMs, dims=3)) do θP, θMs
        y_global, y_pred_i = f(θP, θMs, xP)
        y_pred_i
    end)
end

"""
Generate samples of (inv-transformed) model parameters, ζ, 
and the vector of standard deviations, σ, i.e. the diagonal of the cholesky-factor.

Adds the MV-normally distributed residuals, retrieved by `sample_ζresid_norm`
to the means extracted from parameters and predicted by the machine learning
model. 

The output shape of size `(n_site x n_par x n_MC)` is tailored to iterating
each MC sample and then transforming each parameter on block across sites.
"""
function generate_ζ(rng, g, ϕ::AbstractVector{FT}, xM::MT;
    int_μP_ϕg_unc::AbstractComponentArrayInterpreter,
    int_unc::AbstractComponentArrayInterpreter,
    n_MC=3, cor_ends, pbm_covar_indices) where {FT,MT}
    # see documentation of neg_elbo_gtf
    ϕc = int_μP_ϕg_unc(CA.getdata(ϕ))
    μ_ζP = CA.getdata(ϕc.μP)
    ϕg = CA.getdata(ϕc.ϕg)
    # first pass: append μ_ζP_to covars, need ML prediction for magnitude of ζMs
    # TODO replace pbm_covar_indices by ComponentArray? dimensions to be type-inferred?
    xMP0 = _append_each_covars(xM, CA.getdata(μ_ζP), pbm_covar_indices)
    μ_ζMs0 = g(xMP0, ϕg)::MT # for gpu restructure returns Any, so apply type
    ζP_resids, ζMs_parfirst_resids, σ = sample_ζresid_norm(rng, μ_ζP, μ_ζMs0, ϕc.unc; n_MC, cor_ends, int_unc)
    if pbm_covar_indices isa SA.SVector{0}
        # do not need to predict again but just add the residuals to μ_ζP and μ_ζMs
        ζsP = (μ_ζP .+ ζP_resids)  # n_par x n_MC 
        ζsMs = permutedims(μ_ζMs0 .+ ζMs_parfirst_resids, (2, 1, 3)) # n_site x n_par x n_MC
    else
        #rP, rMs = first(zip(eachcol(ζP_resids), eachslice(ζMs_parfirst_resids;dims=3)))
        ζst = map(eachcol(ζP_resids), eachslice(ζMs_parfirst_resids; dims=3)) do rP, rMs
            ζP = μ_ζP .+ rP
            # second pass: append ζP rather than μ_ζP to covars to xM
            xMP = _append_each_covars(xM, CA.getdata(ζP), pbm_covar_indices)
            μ_ζMst = g(xMP, ϕg)::MT # for gpu restructure returns Any, so apply type
            ζMs = (μ_ζMst .+ rMs)'  # already transform to par-last form
            ζP, ζMs
        end
        # ζsP = stack(map(first, ζst); dims=1)  # n_MC x n_par
        # ζsMs = stack(map(x -> x[2], ζst); dims=1) # n_MC x n_site x n_par
        ζsP = stack(map(first, ζst))  # n_par x n_MC
        ζsMs = stack(map(x -> x[2], ζst)) # n_site x n_par x n_MC
    end
    ζsP, ζsMs, σ
end

# function _append_PBM_covars(xM, ζP, pbm_covars::NTuple{N,Symbol}) where N
#     #@show ζP, typeof(ζP)
#     vcat(xM, hcat(fill(
#         convert(Array{eltype(xM)}, CA.getdata(ζP[pbm_covars])),
#         #similar(CA.getdata(ζP[pbm_covars]), eltype(xM)), # 
#         size(xM,2))...))
# end
# function _append_PBM_covars(xM, ζP, pbm_covars::NTuple{0}) 
#     xM
# end

function _append_each_covars(xM, ζP::AbstractVector, pbm_covar_indices::SA.StaticVector{0})
    xM
end
function _append_each_covars(xM, ζP::AbstractVector, pbm_covar_indices::AbstractVector)
    ζP_covar = ζP[pbm_covar_indices]
    _append_each_covars(xM, ζP_covar)
end
function _append_each_covars(xM, ζP_covar::AbstractVector)
    #@show ζP, typeof(ζP)
    @assert eltype(xM) == eltype(ζP_covar)
    #Main.@infiltrate_main
    ζP_rep = reduce(hcat, fill(ζP_covar, size(xM, 2)))
    vcat(xM, ζP_rep)
end

function get_pbm_covar_indices(ζP, pbm_covars::NTuple{N,Symbol},
    intP::AbstractComponentArrayInterpreter=ComponentArrayInterpreter(ζP)) where {N}
    #SA.SVector{N}(CA.getdata(intP(1:length(intP))[pbm_covars])) # can not index into GPUarr
    CA.getdata(intP(1:length(intP))[pbm_covars])
end
function get_pbm_covar_indices(ζP, pbm_covars::NTuple{0},
    intP::AbstractComponentArrayInterpreter=ComponentArrayInterpreter(ζP))
    SA.SA[]
end

# function _predict_μ_ζMs(xM, ζP, pbm_covars::NTuple{N,Symbol}, g, ϕg, μ_ζMs0) where N
#     xMP2 = _append_PBM_covars(xM, ζP, pbm_covars) # need different variable name?
#     μ_ζMs = g(xMP2, ϕg)
# end
# function _predict_μ_ζMs(xM, ζP, pbm_covars::NTuple{0}, g, ϕg, μ_ζMs0)
#     # if pbm_covars is the empty tuple, just return the original prediction on xM only
#     # rather than calling the ML model
#     μ_ζMs0
# end

function _predict_μ_ζMs(xM, ζP, pbm_covar_indices::AbstractVector, g, ϕg, μ_ζMs0)
    xMP2 = _append_each_covars(xM, CA.getdata(ζP), pbm_covar_indices)
    μ_ζMs = g(xMP2, ϕg)
end
function _predict_μ_ζMs(xM, ζP, pbm_covars_indices::SA.StaticVector{0}, g, ϕg, μ_ζMs0)
    # if pbm_covars is the empty tuple, just return the original prediction on xM only
    # rather than calling the ML model
    μ_ζMs0
end

"""
Extract relevant parameters from ζ and return n_MC generated multivariate normal draws
together with the vector of standard deviations, `σ`: `(ζP_resids, ζMs_parfirst_resids, σ)`
The output shape `(n_θ, n_site?, n_MC)` is tailored to adding `ζMs_parfirst_resids` to
ML-model predcitions of size `(n_θM, n_site)`.

## Arguments
* `int_unc`: Interpret vector as ComponentVector with components
   ρsP, ρsM, logσ2_logP, coef_logσ2_ζMs(intercept + slope), 
"""
function sample_ζresid_norm(rng::Random.AbstractRNG, ζP::AbstractVector, ζMs::AbstractMatrix,
    args...; n_MC, cor_ends, int_unc)
    n_θP, n_θMs = length(ζP), length(ζMs)
    # intm_PMs_parfirst = !isnothing(intm_PMs_parfirst) ? intm_PMs_parfirst : begin
    #     n_θM, n_site_batch = size(ζMs)
    #     get_concrete(ComponentArrayInterpreter(
    #         P = (n_MC, n_θP), Ms = (n_MC, n_θM, n_site_batch)))
    # end
    urandn = _create_randn(rng, CA.getdata(ζP), n_MC, n_θP + n_θMs)
    sample_ζresid_norm(urandn, CA.getdata(ζP), CA.getdata(ζMs), args...;
        cor_ends, int_unc=get_concrete(int_unc))
end

function sample_ζresid_norm(urandn::AbstractMatrix, ζP::TP, ζMs::TM,
    ϕunc::AbstractVector;
    int_unc=get_concrete(ComponentArrayInterpreter(ϕunc)),
    cor_ends
) where {T,TP<:AbstractVector{T},TM<:AbstractMatrix{T}}
    ϕuncc = int_unc(CA.getdata(ϕunc))
    n_θP, n_θMs, (n_θM, n_batch) = length(ζP), length(ζMs), size(ζMs)
    n_MC = size(urandn, 1) # TODO transform urandn
    # do not create a UpperTriangular Matrix of an AbstractGÜUArray in transformU_cholesky1
    ρsP = isempty(ϕuncc.ρsP) ? similar(ϕuncc.ρsP) : ϕuncc.ρsP # required by zygote
    UP = transformU_block_cholesky1(ρsP, cor_ends.P)
    ρsM = isempty(ϕuncc.ρsM) ? similar(ϕuncc.ρsM) : ϕuncc.ρsM # required by zygote
    UM = transformU_block_cholesky1(ρsM, cor_ends.M)
    cf = ϕuncc.coef_logσ2_ζMs
    logσ2_logMs = vec(cf[1, :] .+ cf[2, :] .* ζMs)
    logσ2_logP = vec(CA.getdata(ϕuncc.logσ2_logP))
    # CUDA cannot multiply BlockDiagonal * Diagonal, construct already those blocks
    σMs = reshape(exp.(logσ2_logMs ./ 2), n_θM, :)
    σP = exp.(logσ2_logP ./ 2)
    # BlockDiagonal does work with CUDA, but not with combination of Zygote and CUDA
    # need to construct full matrix for CUDA
    Uσ = _create_blockdiag(UP, UM, σP, σMs, n_batch)
    σ = diag(Uσ)   # elements of the diagonal: standard deviations
    ζ_resids_parfirst = Uσ' * urandn' # n_par x n_MC
    #ζ_resids_parfirst = urandn * Uσ # n_MC x n_par
    ζP_resids = ζ_resids_parfirst[1:n_θP, :]
    ζMs_parfirst_resids = reshape(ζ_resids_parfirst[(n_θP+1):end, :], n_θM, n_batch, n_MC)
    ζP_resids, ζMs_parfirst_resids, σ
    # #map(std, eachcol(ζ_resids_parfirst[:, 3:8]))
    # ζ_resid = transpose_mPMs_sitefirst(ζ_resids_parfirst; intm_PMs_parfirst)
    # #map(std, eachcol(ζ_resid[:, 3:8])) # all ~ 0.1 in sample_ζresid_norm cpu
    # #map(std, eachcol(ζ_resid[:, 2 + n_batch .+ (-1:5)])) # all ~ 100, except first two
    # # returns AbstractGPUuArrays to either continue on GPU or need to transfer to CPU
    # ζ_resid, σ
end

"""
Transforms each row of a matrix (n_MC x n_Par) with site parameters Ms inside n_Par 
of form (n_par x n_site) to Ms of the form (n_site x n_par), i.e. 
neighboring entries (inside a column) are of the same parameter.

This format of having n_par as the last dimension helps transforming parameters
on block.
"""
function transpose_mPMs_sitefirst(Xt, n_θP::Integer, n_θM, n_site_batch, n_MC)
    # cannot make n_θP keyword arguments, because it overrides method below
    intm_PMs_parfirst = ComponentArrayInterpreter(
        P=(n_MC, n_θP), Ms=(n_MC, n_θM, n_site_batch))
    transpose_mPMs_sitefirst(Xt; intm_PMs_parfirst)
end
function transpose_mPMs_sitefirst(Xt;
    intm_PMs_parfirst=ComponentArrayInterpreter(
        P=(n_MC, n_θP), Ms=(n_MC, n_θM, n_site_batch))
)
    Xtc = intm_PMs_parfirst(Xt)
    # Main.@infiltrate_main

    # _Ms = Xtc.Ms
    # map(std, eachrow(_Ms[:,1:6,:]))

    # map(std, eachrow(tmp[3:8,:]))
    # _Ms = permutedims(Xtc.Ms, (1, 3, 2))
    X_site_first = CA.ComponentVector(P=Xtc.P, Ms=permutedims(Xtc.Ms, (1, 3, 2)))
    reshape(CA.getdata(X_site_first), size(Xt))::typeof(CA.getdata(Xt))
    # X_site_first = CA.ComponentVector(
    #     P = permutedims(Xtc.P), Ms = permutedims(Xtc.Ms, (3, 2, 1)))
    # reshape(CA.getdata(X_site_first), rev(size(Xt)))::typeof(CA.getdata(Xt))
end

function _create_blockdiag(UP::AbstractMatrix{T}, UM, σP, σMs, n_batch) where {T}
    v = [i == 0 ? UP * Diagonal(σP) : UM * Diagonal(σMs[:, i]) for i in 0:n_batch]
    BlockDiagonal(v)
end
function _create_blockdiag(
    UP::GPUArraysCore.AbstractGPUMatrix{T}, UM, σP, σMs, n_batch) where {T}
    # using BlockDiagonal leads to Scalar operations downstream
    # v = [i == 0 ? UP * Diagonal(σP) : UM * Diagonal(σMs[:, i]) for i in 0:n_batch]
    # BlockDiagonal(v)    
    # Uσ = cat([i == 0 ? UP * Diagonal(σP) : UM * Diagonal(σMs[:, i]) for i in 0:n_batch]...;
    #     dims=(1, 2))
    # on GPU use only one big multiplication rather than many small ones
    U = cat([i == 0 ? UP : UM for i in 0:n_batch]...; dims=(1, 2))
    #Main.@infiltrate_main
    σD = Diagonal(vcat(σP, vec(σMs)))
    Uσ = U * σD
    # need for Zygote why?
    # tmp = cat(Uσ; dims=(1,2))
    tmp = vcat(Uσ)
end

function _create_randn(rng, ::AbstractVector{T}, dims...) where {T}
    randn(rng, T, dims...)
end

#moved to HybridVariationalInferenceCUDAExt
#function _create_randn(rng, ::CUDA.CuVector{T}, dims...) where {T}

"""
Transform parameters and compute absolute of determinant of Jacobian of the transformation.
- from unconstrained (e.g. log) ζ scale of format (n_site x n_par)
- to constrained θ scale of format (n_site x n_par)
"""

function transform_and_logjac_ζ(ζP::AbstractVector, ζMs::AbstractMatrix;
    transP::Bijectors.Transform,
    transMs::StackedArray=StackedArray(transM, size(ζMs, 1)))
    θP, logjac_P = Bijectors.with_logabsdet_jacobian(transP, ζP)
    θMs, logjac_M = Bijectors.with_logabsdet_jacobian(transMs, ζMs)
    θP, θMs, logjac_P + logjac_M
end

"""
Transform parameters 
- from unconstrained (e.g. log) ζ scale of format ((n_site x n_par) x n_mc)
- to constrained θ scale of the same format
"""
function transform_ζs(ζsP::AbstractMatrix, ζsMs::AbstractArray;
    trans_mP::StackedArray=StackedArray(transP, n_MC),
    trans_mMs::StackedArray=StackedArray(transM, n_MC * n_site_batch)
)
    # transform to parameter-last that can apply transformations effectively
    θsPt = trans_mP(ζsP')
    θsMst = trans_mMs(permutedims(ζsMs, (3, 1, 2)))
    # backtransform to n_mc last for efficient mapping?
    # TODO test if faster than mapping
    θsP = θsPt'
    θsMs = permutedims(θsMst, (2, 3, 1))
    θsP, θsMs
end

function flatten_hybrid_pars(xsP::AbstractMatrix{FT}, xsMs::AbstractArray{FT,3}) where FT
    n_site_pred, n_θM, n_MC = size(xsMs)
    @assert size(xsP,2) == n_MC
    vcat(xsP, reshape(xsMs, n_site_pred * n_θM, n_MC))
end


